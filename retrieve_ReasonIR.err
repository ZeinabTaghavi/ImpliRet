Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:00<00:00,  9.54it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:00<00:00,  9.66it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 12.11it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 103.74it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 103.56it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.10it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.72it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.50it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.81it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.99it/s]
Traceback (most recent call last):
  File "/dss/dsshome1/0B/di38wip/ImpliRet_edited/./Retrieval/retrieve_indexing.py", line 135, in <module>
    save_retriever_indices(args.dataset_folder, args.output_folder, args.track, args.type, args.retriever_name, args.question_type, args.expanded_question_folder)
  File "/dss/dsshome1/0B/di38wip/ImpliRet_edited/./Retrieval/retrieve_indexing.py", line 93, in save_retriever_indices
    retriever = retriever_module(corpus, k=len(corpus))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/ImpliRet_edited/Retrieval/Retrievals/ReasonIR_retriever.py", line 34, in __init__
    self.model = SentenceTransformer(self.llm_model_name, trust_remote_code=True, model_kwargs=self.model_kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py", line 348, in __init__
    self.to(device)
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1355, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 915, in _apply
    module._apply(fn)
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 915, in _apply
    module._apply(fn)
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 915, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 942, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1341, in convert
    return t.to(
           ^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 93.02 GiB of which 17.88 MiB is free. Including non-PyTorch memory, this process has 92.99 GiB memory in use. Of the allocated memory 91.57 GiB is allocated by PyTorch, and 776.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 98.28it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.92it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:00,  3.27it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 11.91it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.64it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.12it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.41it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.37it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.34it/s]
Traceback (most recent call last):
  File "/dss/dsshome1/0B/di38wip/ImpliRet_edited/./Retrieval/retrieve_indexing.py", line 135, in <module>
    save_retriever_indices(args.dataset_folder, args.output_folder, args.track, args.type, args.retriever_name, args.question_type, args.expanded_question_folder)
  File "/dss/dsshome1/0B/di38wip/ImpliRet_edited/./Retrieval/retrieve_indexing.py", line 93, in save_retriever_indices
    retriever = retriever_module(corpus, k=len(corpus))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/ImpliRet_edited/Retrieval/Retrievals/ReasonIR_retriever.py", line 34, in __init__
    self.model = SentenceTransformer(self.llm_model_name, trust_remote_code=True, model_kwargs=self.model_kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py", line 348, in __init__
    self.to(device)
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1355, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 915, in _apply
    module._apply(fn)
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 915, in _apply
    module._apply(fn)
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 915, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 942, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1341, in convert
    return t.to(
           ^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 93.02 GiB of which 69.88 MiB is free. Including non-PyTorch memory, this process has 92.94 GiB memory in use. Of the allocated memory 91.46 GiB is allocated by PyTorch, and 836.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.69it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.38it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 98.43it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.85it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.83it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 84.69it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.32it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.14it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.63it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.53it/s]
Traceback (most recent call last):
  File "/dss/dsshome1/0B/di38wip/ImpliRet_edited/./Retrieval/retrieve_indexing.py", line 135, in <module>
    save_retriever_indices(args.dataset_folder, args.output_folder, args.track, args.type, args.retriever_name, args.question_type, args.expanded_question_folder)
  File "/dss/dsshome1/0B/di38wip/ImpliRet_edited/./Retrieval/retrieve_indexing.py", line 93, in save_retriever_indices
    retriever = retriever_module(corpus, k=len(corpus))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/ImpliRet_edited/Retrieval/Retrievals/ReasonIR_retriever.py", line 34, in __init__
    self.model = SentenceTransformer(self.llm_model_name, trust_remote_code=True, model_kwargs=self.model_kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py", line 348, in __init__
    self.to(device)
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1355, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 915, in _apply
    module._apply(fn)
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 915, in _apply
    module._apply(fn)
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 915, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 942, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1341, in convert
    return t.to(
           ^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 93.02 GiB of which 49.88 MiB is free. Including non-PyTorch memory, this process has 92.96 GiB memory in use. Of the allocated memory 91.46 GiB is allocated by PyTorch, and 856.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.74it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.15it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.60it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.13it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.56it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.79it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.48it/s]
Traceback (most recent call last):
  File "/dss/dsshome1/0B/di38wip/ImpliRet_edited/./Retrieval/retrieve_indexing.py", line 135, in <module>
    save_retriever_indices(args.dataset_folder, args.output_folder, args.track, args.type, args.retriever_name, args.question_type, args.expanded_question_folder)
  File "/dss/dsshome1/0B/di38wip/ImpliRet_edited/./Retrieval/retrieve_indexing.py", line 93, in save_retriever_indices
    retriever = retriever_module(corpus, k=len(corpus))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/ImpliRet_edited/Retrieval/Retrievals/ReasonIR_retriever.py", line 34, in __init__
    self.model = SentenceTransformer(self.llm_model_name, trust_remote_code=True, model_kwargs=self.model_kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py", line 348, in __init__
    self.to(device)
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1355, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 915, in _apply
    module._apply(fn)
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 915, in _apply
    module._apply(fn)
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 915, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 942, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1341, in convert
    return t.to(
           ^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 93.02 GiB of which 69.88 MiB is free. Including non-PyTorch memory, this process has 92.94 GiB memory in use. Of the allocated memory 91.46 GiB is allocated by PyTorch, and 836.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.78it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.81it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 92.47it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 98.03it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.07it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.82it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.89it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.84it/s]
Traceback (most recent call last):
  File "/dss/dsshome1/0B/di38wip/ImpliRet_edited/./Retrieval/retrieve_indexing.py", line 135, in <module>
    save_retriever_indices(args.dataset_folder, args.output_folder, args.track, args.type, args.retriever_name, args.question_type, args.expanded_question_folder)
  File "/dss/dsshome1/0B/di38wip/ImpliRet_edited/./Retrieval/retrieve_indexing.py", line 93, in save_retriever_indices
    retriever = retriever_module(corpus, k=len(corpus))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/ImpliRet_edited/Retrieval/Retrievals/ReasonIR_retriever.py", line 34, in __init__
    self.model = SentenceTransformer(self.llm_model_name, trust_remote_code=True, model_kwargs=self.model_kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py", line 348, in __init__
    self.to(device)
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1355, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 915, in _apply
    module._apply(fn)
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 915, in _apply
    module._apply(fn)
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 915, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 942, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1341, in convert
    return t.to(
           ^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 93.02 GiB of which 81.88 MiB is free. Including non-PyTorch memory, this process has 92.93 GiB memory in use. Of the allocated memory 91.46 GiB is allocated by PyTorch, and 824.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 99.18it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 98.61it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 98.74it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.84it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.48it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.89it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.97it/s]
Traceback (most recent call last):
  File "/dss/dsshome1/0B/di38wip/ImpliRet_edited/./Retrieval/retrieve_indexing.py", line 135, in <module>
    save_retriever_indices(args.dataset_folder, args.output_folder, args.track, args.type, args.retriever_name, args.question_type, args.expanded_question_folder)
  File "/dss/dsshome1/0B/di38wip/ImpliRet_edited/./Retrieval/retrieve_indexing.py", line 93, in save_retriever_indices
    retriever = retriever_module(corpus, k=len(corpus))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/ImpliRet_edited/Retrieval/Retrievals/ReasonIR_retriever.py", line 34, in __init__
    self.model = SentenceTransformer(self.llm_model_name, trust_remote_code=True, model_kwargs=self.model_kwargs)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py", line 348, in __init__
    self.to(device)
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1355, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 915, in _apply
    module._apply(fn)
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 915, in _apply
    module._apply(fn)
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 915, in _apply
    module._apply(fn)
  [Previous line repeated 3 more times]
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 942, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/dss/dsshome1/0B/di38wip/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1341, in convert
    return t.to(
           ^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 93.02 GiB of which 69.88 MiB is free. Including non-PyTorch memory, this process has 92.94 GiB memory in use. Of the allocated memory 91.46 GiB is allocated by PyTorch, and 836.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
