# ────────────────────────────── core ───────────────────────────────
python>=3.9
numpy>=1.23
pandas>=1.5
PyYAML>=6.0
tqdm>=4.66
scikit-learn>=1.3
rich>=13.7          # pretty CLI output & progress logging
click>=8.1          # optional: nicer argument parsing
jsonargparse==4.34.0   # YAML/CLI parsing exactly as in NoLiMa
tenacity==9.0.0        # retry/back-off helper

# ─────────────── dataset generation (synthetic benchmark) ──────────
faker>=24.9         # random names, dates, etc. for implicit facts
sentence-transformers>=2.7  # optional semantic template expansion

# ───────────────────────── retrieval baselines ─────────────────────
pyserini==0.20.0            # Lucene/BM25, DPR, SPLADE, etc.
faiss-cpu>=1.7              # dense-vector indexing
elasticsearch>=8.11         # ES / OpenSearch client
ir_measures>=0.3.2          # MAP, nDCG, Recall, …

# ───────────────────── LLM reasoning experiments ───────────────────
openai>=1.14                # GPT-3.5 / GPT-4 API
langchain>=0.1.0            # LC JSON prompt schema + orchestration
transformers>=4.40
torch>=2.0
tiktoken>=0.7               # fast GPT token counting
vllm>=0.4.2                 # local vLLM (in-process)

# ────────────────────────── reporting utils ────────────────────────
tabulate>=0.9               # pretty tables in reports
