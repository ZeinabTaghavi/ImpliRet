# ───────────────────────── core async / CLI ──────────────────────────
jsonargparse==4.34.0   # YAML/CLI parsing exactly as in NoLiMa
tenacity==9.0.0        # retry/back-off helper

# ───────────────────────── model back-ends ────────────────────────────
openai>=1.12.0         # AsyncOpenAI + AsyncAzureOpenAI clients
tiktoken>=0.7.0        # OpenAI tokeniser
transformers>=4.46.1   # HF tokeniser & hf-local inference
torch>=2.1.0           # required by transformers / local-vLLM

# local vLLM (in-process) – use latest stable
vllm>=0.4.2

# ───────────────────────── utility libs ───────────────────────────────
numpy>=1.25.0

# (optional) Ray – only needed if you launch local-vLLM with
# distributed_executor_backend="ray".  Comment out if unused.
# ray==2.9.0

# Then run: pip install -r requirements.txt