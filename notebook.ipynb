{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e2d3a3d",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ§ª ImpliRetÂ Evaluation Notebook\n",
    "\n",
    "This tutorial lets you:\n",
    "\n",
    "1. **Load** any of the six ImpliRet subsets.\n",
    "2. **Index & evaluate** the builtâ€‘in retrievers (BM25, ColBERTâ€‘v2, Contriever, Dragon+, HippoRAGÂ 2, ReasonIRâ€‘8B).\n",
    "3. **Run longâ€‘context or RAGâ€‘style readers** (Llamaâ€‘3, GPTâ€‘4.1, etc.) against the retrieved docs.\n",
    "4. **Export** metrics toÂ `metrics/latest.json` so the README badges stay in sync.\n",
    "\n",
    "> **Tip**: Run on âš¡Â Colab GPU for fastest turnaround.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2c6ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Install dependencies (â‰ˆÂ 1Â min)\n",
    "# collapse-hide\n",
    "DEVICE = \"cuda\"  #@param [\"cuda\", \"cpu\"]\n",
    "!pip -q install -r https://raw.githubusercontent.com/ZeinabTaghavi/ImpliRet/main/requirements.txt\n",
    "\n",
    "import os, json, pathlib, itertools, pprint, time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f238e8",
   "metadata": {},
   "source": [
    "## 1Â Â·Â Load a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e6007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "SPLIT = \"arithmetic\"       #@param [\"arithmetic\", \"wknow\", \"temporal\"]\n",
    "STYLE = \"multispeaker\"     #@param [\"multispeaker\", \"unispeaker\"]\n",
    "\n",
    "ds = load_dataset(\"zeinabTaghavi/ImpliRet\", name=STYLE, split=SPLIT)\n",
    "print(f\"Loaded {len(ds):,} examples  |  Columns â†’ {list(ds.features.keys())}\")\n",
    "print(\"\\nSample question â†’\", ds[0][\"question\"])\n",
    "print(\"Implicit document snippet â†’\", ds[0][\"pos_document\"][:200], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692487d3",
   "metadata": {},
   "source": [
    "## 2Â Â·Â Run a single retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db93767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Retrieval.retrieve_indexing import index_and_save\n",
    "from Retrieval.reporting import evaluate_run, save_metrics_table\n",
    "\n",
    "OUTPUT = pathlib.Path(\"Retrieval/results\")\n",
    "OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RETRIEVER = \"bm25\"      #@param [\"bm25\", \"colbert\", \"contriever\", \"dragon_plus\", \"hipporag2\", \"reasonir8b\"]\n",
    "\n",
    "run_file = index_and_save(\n",
    "    output_folder=str(OUTPUT),\n",
    "    category=SPLIT,\n",
    "    discourse=STYLE,\n",
    "    retriever_name=RETRIEVER,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "metrics = evaluate_run(run_file)\n",
    "pprint.pp(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb86237",
   "metadata": {},
   "source": [
    "## 3Â Â·Â Benchmark all builtâ€‘ins (optional, takes time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ac35ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_RETRIEVERS = [\"bm25\", \"colbert\", \"contriever\", \"dragon_plus\", \"hipporag2\", \"reasonir8b\"]\n",
    "table = {}\n",
    "\n",
    "for r in ALL_RETRIEVERS:\n",
    "    run_file = index_and_save(str(OUTPUT), SPLIT, STYLE, r, DEVICE)\n",
    "    table[r] = evaluate_run(run_file)[\"ndcg@10\"]\n",
    "    \n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d568ecec",
   "metadata": {},
   "source": [
    "### Visualise nDCG@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08589f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.bar(table.keys(), table.values())\n",
    "plt.ylabel(\"nDCG@10 â†‘\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(f\"{STYLE}-{SPLIT}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689becb2",
   "metadata": {},
   "source": [
    "## 4Â Â·Â RAG / Longâ€‘context Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddab774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RAG_Style.scripts.sync.sync_run_tests import run_single_experiment\n",
    "CONFIG = \"RAG_Style/experiment_configs/bm/A_Multi_llama_bm_10.yaml\"\n",
    "\n",
    "result_path = run_single_experiment(CONFIG, hf_token=os.getenv(\"HF_TOKEN\", \"\"))\n",
    "print(\"Saved generations â†’\", result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de751f9",
   "metadata": {},
   "source": [
    "### Compute ROUGEâ€‘1 recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a3c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RAG_Style.scripts.reporting import rouge_report\n",
    "\n",
    "rouge_metrics = rouge_report(result_path)\n",
    "print(rouge_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11172c07",
   "metadata": {},
   "source": [
    "## 5Â Â·Â Export metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67efa9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = {\n",
    "    \"retrieval\": {\"ndcg10\": {\"avg\": sum(table.values())/len(table)}},\n",
    "    \"rag\": {\"rouge1\": {\"avg\": rouge_metrics[\"rouge1\"]}}\n",
    "}\n",
    "with open(\"metrics/latest.json\", \"w\") as f:\n",
    "    json.dump(latest, f, indent=2)\n",
    "print(\"Wrote metrics/latest.json\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
