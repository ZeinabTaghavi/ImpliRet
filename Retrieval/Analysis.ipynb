{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved records file\n",
    "with open('./reports/retrieval_analysis.json', 'r') as f:\n",
    "    records = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since zeinabTaghavi/ImpliRet couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'unispeaker' at /mounts/Users/cisintern/zeinabtaghavi/.cache/huggingface/datasets/zeinabTaghavi___impli_ret/unispeaker/0.0.0/4396c7e7cc73d91ce1eaa0cc2f6001f847c4c8ad (last modified on Tue Jun 24 18:26:19 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing unispeaker arithmetic bm25\n",
      "results/arithmetic_unispeaker_bm25_index.jsonl\n",
      "Saved analysis results to ./reports/retrieval_analysis.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since zeinabTaghavi/ImpliRet couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'unispeaker' at /mounts/Users/cisintern/zeinabtaghavi/.cache/huggingface/datasets/zeinabTaghavi___impli_ret/unispeaker/0.0.0/4396c7e7cc73d91ce1eaa0cc2f6001f847c4c8ad (last modified on Tue Jun 24 18:26:19 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing unispeaker temporal bm25\n",
      "results/temporal_unispeaker_bm25_index.jsonl\n",
      "Saved analysis results to ./reports/retrieval_analysis.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since zeinabTaghavi/ImpliRet couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'unispeaker' at /mounts/Users/cisintern/zeinabtaghavi/.cache/huggingface/datasets/zeinabTaghavi___impli_ret/unispeaker/0.0.0/4396c7e7cc73d91ce1eaa0cc2f6001f847c4c8ad (last modified on Tue Jun 24 18:26:19 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing unispeaker wknow bm25\n",
      "results/wknow_unispeaker_bm25_index.jsonl\n",
      "Saved analysis results to ./reports/retrieval_analysis.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since zeinabTaghavi/ImpliRet couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'multispeaker' at /mounts/Users/cisintern/zeinabtaghavi/.cache/huggingface/datasets/zeinabTaghavi___impli_ret/multispeaker/0.0.0/84345357f3de42273eb43cd28fa83b143f8f9c0d (last modified on Wed Jun 25 11:29:34 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing multispeaker arithmetic bm25\n",
      "results/arithmetic_multispeaker_bm25_index.jsonl\n",
      "Saved analysis results to ./reports/retrieval_analysis.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since zeinabTaghavi/ImpliRet couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'multispeaker' at /mounts/Users/cisintern/zeinabtaghavi/.cache/huggingface/datasets/zeinabTaghavi___impli_ret/multispeaker/0.0.0/84345357f3de42273eb43cd28fa83b143f8f9c0d (last modified on Wed Jun 25 11:29:34 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing multispeaker temporal bm25\n",
      "results/temporal_multispeaker_bm25_index.jsonl\n",
      "Saved analysis results to ./reports/retrieval_analysis.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since zeinabTaghavi/ImpliRet couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'multispeaker' at /mounts/Users/cisintern/zeinabtaghavi/.cache/huggingface/datasets/zeinabTaghavi___impli_ret/multispeaker/0.0.0/84345357f3de42273eb43cd28fa83b143f8f9c0d (last modified on Wed Jun 25 11:29:34 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing multispeaker wknow bm25\n",
      "results/wknow_multispeaker_bm25_index.jsonl\n",
      "Saved analysis results to ./reports/retrieval_analysis.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "# ----------------------------------\n",
    "# config\n",
    "# ----------------------------------\n",
    "discourse_styles  = [\"unispeaker\", \"multispeaker\"]\n",
    "reasoning_types   = [\"arithmetic\", \"temporal\", \"wknow\"]\n",
    "retrieval_types   = ['bm25']          # keep if you also want BM25 vs ReasonIR                       # how many \"high\" and \"low\"\n",
    "dataset_repo      = \"zeinabTaghavi/ImpliRet\"      # HF dataset\n",
    "results_dir       = \"./results\"                   # retrieval JSONL folder\n",
    "\n",
    "def overlap_count(query, pos_doc): \n",
    "    count = 0\n",
    "    for word in query.split():\n",
    "        for word_pd in pos_doc.split():\n",
    "            if word in word_pd:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "# ----------------------------------\n",
    "# main loop\n",
    "# ----------------------------------\n",
    "import json, pandas as pd\n",
    "from datasets import load_dataset\n",
    "from pathlib  import Path\n",
    "\n",
    "# records = {}\n",
    "window = 50\n",
    "n = 20\n",
    "for discourse in discourse_styles:\n",
    "    for reasoning in reasoning_types:\n",
    "        ds = load_dataset(dataset_repo, name=discourse, split=reasoning)\n",
    "        \n",
    "\n",
    "        for retrieval in retrieval_types:\n",
    "            print(f\"Processing {discourse} {reasoning} {retrieval}\")\n",
    "            records[f\"{discourse}_{reasoning}_{retrieval}\"] = {}\n",
    "            # ---------- locate the retrieval file ----------\n",
    "            # pattern used in your earlier example:\n",
    "            #   arithmetic_multispeaker_bm25_index.jsonl\n",
    "            run_file = Path(results_dir) / f\"{reasoning}_{discourse}_{retrieval}_index.jsonl\"\n",
    "            print(run_file)\n",
    "            if not run_file.exists():\n",
    "                print(f\"⚠️  Missing run file → {run_file}\")\n",
    "                continue\n",
    "\n",
    "            # ---------- read the retrieval scores ----------\n",
    "            top_w = []\n",
    "            top_w_score = []\n",
    "            low_w = []\n",
    "            low_w_score = []\n",
    "            i_average_score = {}\n",
    "            with run_file.open() as fh:\n",
    "                run_lines = []\n",
    "                for line in fh:\n",
    "                    new_line = json.loads(line)['index_score_tuple_list']\n",
    "                    run_lines.append(new_line)\n",
    "                    new_line.sort(key=lambda x: x[1], reverse=True)\n",
    "                    top_w.extend([new_line[num][0] for num in range(window)])\n",
    "                    top_w_score.extend([new_line[num][1] for num in range(window)])\n",
    "                    low_w.extend([new_line[-(num+1)][0] for num in range(window)])\n",
    "                    low_w_score.extend([new_line[-(num+1)][1] for num in range(window)])\n",
    "                    \n",
    "                    for idx, i in enumerate(new_line):\n",
    "                        if i[0] in i_average_score.keys():\n",
    "                            if idx> i_average_score[i[0]]['max']:\n",
    "                                i_average_score[i[0]]['max'] =  idx\n",
    "                            if  idx < i_average_score[i[0]]['min']:\n",
    "                                i_average_score[i[0]]['min'] =  idx\n",
    "                            i_average_score[i[0]]['sum'] +=  idx\n",
    "                            i_average_score[i[0]]['count'] += 1\n",
    "                            i_average_score[i[0]]['dist'] = i_average_score[i[0]]['max'] - i_average_score[i[0]]['min']\n",
    "                        else:\n",
    "                            i_average_score[i[0]] = {'max': idx, 'min': idx, 'sum': idx, 'count': 1, 'dist': 0}\n",
    "\n",
    "            i_average_dist = sum([i_average_score[i]['dist'] for i in i_average_score.keys()])/len(i_average_score.keys())\n",
    "            records[f\"{discourse}_{reasoning}_{retrieval}\"]['i_average_dist'] = i_average_dist\n",
    "            # Get frequency count of numbers in top_10\n",
    "            frequency = Counter(top_w)\n",
    "            # Get most and least common numbers and their counts\n",
    "            most_common_high = frequency.most_common()[:n]\n",
    "            agv_repeat_high = sum([i[1] for i in most_common_high])/len(most_common_high)\n",
    "            records[f\"{discourse}_{reasoning}_{retrieval}\"]['agv_repeat_high'] = agv_repeat_high\n",
    "            frequency = Counter(low_w)  \n",
    "            most_common_low = frequency.most_common()[:n]\n",
    "            agv_repeat_low = sum([i[1] for i in most_common_low])/len(most_common_low)\n",
    "            records[f\"{discourse}_{reasoning}_{retrieval}\"]['agv_repeat_low'] = agv_repeat_low\n",
    "\n",
    "\n",
    "            # word overlap between query and top_n\n",
    "            \n",
    "            high_score_overlap = 0\n",
    "            low_score_overlap = 0\n",
    "            for i in range(n):\n",
    "                for j in range(len(ds)):\n",
    "                    high_score_overlap += overlap_count(ds[j]['question'], ds[most_common_high[i][0]]['pos_document'])\n",
    "                    low_score_overlap += overlap_count(ds[j]['question'], ds[most_common_low[i][0]]['pos_document'])\n",
    "            high_score_overlap = high_score_overlap/(n*len(ds))\n",
    "            low_score_overlap = low_score_overlap/(n*len(ds))\n",
    "\n",
    "            records[f\"{discourse}_{reasoning}_{retrieval}\"]['high_score_overlap'] = high_score_overlap\n",
    "            records[f\"{discourse}_{reasoning}_{retrieval}\"]['low_score_overlap'] = low_score_overlap\n",
    "         \n",
    "\n",
    "        # Save records to reports directory\n",
    "        import json\n",
    "        import os\n",
    "\n",
    "        # Create reports directory if it doesn't exist\n",
    "        os.makedirs('./reports', exist_ok=True)\n",
    "\n",
    "        # Save records as JSON file\n",
    "        output_path = os.path.join('./reports', 'retrieval_analysis.json')\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(records, f, indent=4)\n",
    "\n",
    "        print(f'Saved analysis results to {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved analysis results to ./reports/retrieval_analysis.json\n"
     ]
    }
   ],
   "source": [
    "# Save records to reports directory\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Create reports directory if it doesn't exist\n",
    "os.makedirs('./reports', exist_ok=True)\n",
    "\n",
    "# Save records as JSON file\n",
    "output_path = os.path.join('./reports', 'retrieval_analysis.json')\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(records, f, indent=4)\n",
    "\n",
    "print(f'Saved analysis results to {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Retrieval/results/temporal_multispeaker_hipporag_index.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[183]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load and examine temporal_multispeaker_hipporag results\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mRetrieval/results/temporal_multispeaker_hipporag_index.jsonl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      3\u001b[39m     lines = f.readlines()\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(lines))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:325\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Retrieval/results/temporal_multispeaker_hipporag_index.jsonl'"
     ]
    }
   ],
   "source": [
    "# Load and examine temporal_multispeaker_hipporag results\n",
    "with open('Retrieval/results/temporal_multispeaker_hipporag_index.jsonl', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    print(len(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # \"unispeaker_arithmetic_hipporag\": {\n",
    "    #     \"i_average_dist\": 0.8630152666666666,\n",
    "    #     \"agv_repeat_high\": 383.35,\n",
    "    #     \"agv_repeat_low\": 726.1,\n",
    "    #     \"high_score_overlap\": 8.054,\n",
    "    #     \"low_score_overlap\": 7.031\n",
    "    # }\n",
    "\n",
    "    # \"multispeaker_arithmetic_hipporag\": {\n",
    "    #     \"i_average_dist\": 0.8242842666666667,\n",
    "    #     \"agv_repeat_high\": 450.65,\n",
    "    #     \"agv_repeat_low\": 861.0,\n",
    "    #     \"high_score_overlap\": 39.855,\n",
    "    #     \"low_score_overlap\": 36.705\n",
    "    # },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
