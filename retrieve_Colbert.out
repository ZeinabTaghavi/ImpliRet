----------------------------  ColBERT  ----------------------------------
Retrieving for track A, type Multi, retriever_name colbert

#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the smartphone that cost $1950? were priced at $1,950?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 26381,  2008,  3465,  1002,  3925,
         1029,  2020, 21125,  2012,  1002,  1015,  1010, 20317,  1029,   102,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the laptop that cost $2150? were priced at $2,150?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 12191,  2008,  3465,  1002, 17405,
         2692,  1029,  2020, 21125,  2012,  1002,  1016,  1010,  5018,  1029,
          102,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the television that cost $450? were priced at $450?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  2547,  2008,  3465,  1002, 10332,
         1029,  2020, 21125,  2012,  1002, 10332,  1029,   102,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the headphones that cost $950? were priced at $950?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  2132, 19093,  2008,  3465,  1002,
        20317,  1029,  2020, 21125,  2012,  1002, 20317,  1029,   102,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the smartwatch that cost $2150? were priced at $2,150?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  6047, 18866,  2008,  3465,  1002,
        17405,  2692,  1029,  2020, 21125,  2012,  1002,  1016,  1010,  5018,
         1029,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the digital camera that cost $2550? were priced at $2,550?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  3617,  4950,  2008,  3465,  1002,
        20637,  2692,  1029,  2020, 21125,  2012,  1002,  1016,  1010, 13274,
         1029,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the gaming console that cost $1650? were priced at $1,650?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 10355, 10122,  2008,  3465,  1002,
        21875,  1029,  2020, 21125,  2012,  1002,  1015,  1010, 13757,  1029,
          102,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the tablet that cost $2050? were priced at $2,050?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 13855,  2008,  3465,  1002, 16327,
         2692,  1029,  2020, 21125,  2012,  1002,  1016,  1010, 28714,  1029,
          102,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the bluetooth speaker that cost $2950? were priced at $2,950?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  2630, 19392,  5882,  2008,  3465,
         1002, 21679,  2692,  1029,  2020, 21125,  2012,  1002,  1016,  1010,
        20317,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the e-reader that cost $250? were priced at $250?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  1041,  1011,  8068,  2008,  3465,
         1002,  5539,  1029,  2020, 21125,  2012,  1002,  5539,  1029,   102,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the drone that cost $850? were priced at $850?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 18465,  2008,  3465,  1002, 15678,
         1029,  2020, 21125,  2012,  1002, 15678,  1029,   102,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the vr headset that cost $2250? were priced at $2,250?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 27830,  4641,  3388,  2008,  3465,
         1002, 14993,  2692,  1029,  2020, 21125,  2012,  1002,  1016,  1010,
         5539,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the action camera that cost $2450? were priced at $2,450?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  2895,  4950,  2008,  3465,  1002,
        21005,  2692,  1029,  2020, 21125,  2012,  1002,  1016,  1010, 10332,
         1029,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the projector that cost $2350? were priced at $2,350?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  2622,  2953,  2008,  3465,  1002,
        17825,  2692,  1029,  2020, 21125,  2012,  1002,  1016,  1010,  8698,
         1029,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the router that cost $1050? were priced at $1,050?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  2799,  2099,  2008,  3465,  1002,
         8746,  2692,  1029,  2020, 21125,  2012,  1002,  1015,  1010, 28714,
         1029,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the coffee maker that cost $650? were priced at $650?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  4157,  9338,  2008,  3465,  1002,
        13757,  1029,  2020, 21125,  2012,  1002, 13757,  1029,   102,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the microwave oven that cost $2550? were priced at $2,550?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 18302, 17428,  2008,  3465,  1002,
        20637,  2692,  1029,  2020, 21125,  2012,  1002,  1016,  1010, 13274,
         1029,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the air fryer that cost $350? were priced at $350?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  2250, 14744,  2121,  2008,  3465,
         1002,  8698,  1029,  2020, 21125,  2012,  1002,  8698,  1029,   102,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the blender that cost $650? were priced at $650?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 12586,  2121,  2008,  3465,  1002,
        13757,  1029,  2020, 21125,  2012,  1002, 13757,  1029,   102,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the vacuum cleaner that cost $1350? were priced at $1,350?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 11641, 20133,  2008,  3465,  1002,
        11502,  2692,  1029,  2020, 21125,  2012,  1002,  1015,  1010,  8698,
         1029,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the desk lamp that cost $1550? were priced at $1,550?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  4624, 10437,  2008,  3465,  1002,
        26245,  1029,  2020, 21125,  2012,  1002,  1015,  1010, 13274,  1029,
          102,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the office chair that cost $650? were priced at $650?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  2436,  3242,  2008,  3465,  1002,
        13757,  1029,  2020, 21125,  2012,  1002, 13757,  1029,   102,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the bookshelf that cost $50? were priced at $50?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  2808, 16001,  2546,  2008,  3465,
         1002,  2753,  1029,  2020, 21125,  2012,  1002,  2753,  1029,   102,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the wall art print that cost $1750? were priced at $1,750?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  2813,  2396,  6140,  2008,  3465,
         1002, 18171,  1029,  2020, 21125,  2012,  1002,  1015,  1010,  9683,
         1029,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the wristwatch that cost $250? were priced at $250?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  7223, 18866,  2008,  3465,  1002,
         5539,  1029,  2020, 21125,  2012,  1002,  5539,  1029,   102,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the backpack that cost $150? were priced at $150?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 13383,  2008,  3465,  1002,  5018,
         1029,  2020, 21125,  2012,  1002,  5018,  1029,   102,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the suitcase that cost $2150? were priced at $2,150?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 15940,  2008,  3465,  1002, 17405,
         2692,  1029,  2020, 21125,  2012,  1002,  1016,  1010,  5018,  1029,
          102,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the sunglasses that cost $650? were priced at $650?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 17072,  2008,  3465,  1002, 13757,
         1029,  2020, 21125,  2012,  1002, 13757,  1029,   102,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the handbag that cost $1050? were priced at $1,050?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  2192, 16078,  2008,  3465,  1002,
         8746,  2692,  1029,  2020, 21125,  2012,  1002,  1015,  1010, 28714,
         1029,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the wallet that cost $350? were priced at $350?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 15882,  2008,  3465,  1002,  8698,
         1029,  2020, 21125,  2012,  1002,  8698,  1029,   102,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the electric toothbrush that cost $250? were priced at $250?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  3751, 11868, 18623,  2008,  3465,
         1002,  5539,  1029,  2020, 21125,  2012,  1002,  5539,  1029,   102,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the hair dryer that cost $350? were priced at $350?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  2606,  4318,  2121,  2008,  3465,
         1002,  8698,  1029,  2020, 21125,  2012,  1002,  8698,  1029,   102,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the board game that cost $450? were priced at $450?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  2604,  2208,  2008,  3465,  1002,
        10332,  1029,  2020, 21125,  2012,  1002, 10332,  1029,   102,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the guitar that cost $1350? were priced at $1,350?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  2858,  2008,  3465,  1002, 11502,
         2692,  1029,  2020, 21125,  2012,  1002,  1015,  1010,  8698,  1029,
          102,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the bicycle that cost $950? were priced at $950?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 10165,  2008,  3465,  1002, 20317,
         1029,  2020, 21125,  2012,  1002, 20317,  1029,   102,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the yoga mat that cost $1250? were priced at $1,250?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 13272, 13523,  2008,  3465,  1002,
         8732,  2692,  1029,  2020, 21125,  2012,  1002,  1015,  1010,  5539,
         1029,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the dumbbell set that cost $1750? were priced at $1,750?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 12873, 17327,  2275,  2008,  3465,
         1002, 18171,  1029,  2020, 21125,  2012,  1002,  1015,  1010,  9683,
         1029,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the printer that cost $2950? were priced at $2,950?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 15041,  2008,  3465,  1002, 21679,
         2692,  1029,  2020, 21125,  2012,  1002,  1016,  1010, 20317,  1029,
          102,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the computer monitor that cost $550? were priced at $550?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  3274,  8080,  2008,  3465,  1002,
        13274,  1029,  2020, 21125,  2012,  1002, 13274,  1029,   102,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the mechanical keyboard that cost $2650? were priced at $2,650?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  6228,  9019,  2008,  3465,  1002,
        20549,  2692,  1029,  2020, 21125,  2012,  1002,  1016,  1010, 13757,
         1029,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the gaming mouse that cost $2550? were priced at $2,550?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 10355,  8000,  2008,  3465,  1002,
        20637,  2692,  1029,  2020, 21125,  2012,  1002,  1016,  1010, 13274,
         1029,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the telescope that cost $550? were priced at $550?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 12772,  2008,  3465,  1002, 13274,
         1029,  2020, 21125,  2012,  1002, 13274,  1029,   102,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the camping tent that cost $60? were priced at $60?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 13215,  9311,  2008,  3465,  1002,
         3438,  1029,  2020, 21125,  2012,  1002,  3438,  1029,   102,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the cordless drill that cost $750? were priced at $750?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 11601,  3238, 12913,  2008,  3465,
         1002,  9683,  1029,  2020, 21125,  2012,  1002,  9683,  1029,   102,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the lawn mower that cost $450? were priced at $450?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 10168,  9587, 13777,  2008,  3465,
         1002, 10332,  1029,  2020, 21125,  2012,  1002, 10332,  1029,   102,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the refrigerator that cost $1750? were priced at $1,750?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 18097,  2008,  3465,  1002, 18171,
         1029,  2020, 21125,  2012,  1002,  1015,  1010,  9683,  1029,   102,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the washing machine that cost $850? were priced at $850?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996, 12699,  3698,  2008,  3465,  1002,
        15678,  1029,  2020, 21125,  2012,  1002, 15678,  1029,   102,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the dishwasher that cost $260? were priced at $260?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  9841, 28556,  2121,  2008,  3465,
         1002, 13539,  1029,  2020, 21125,  2012,  1002, 13539,  1029,   102,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the air purifier that cost $1650? were priced at $1,650?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  2250, 16405,  3089,  8873,  2121,
         2008,  3465,  1002, 21875,  1029,  2020, 21125,  2012,  1002,  1015,
         1010,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What brand and model of what was the brand and model of the electric scooter that cost $850? were priced at $850?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  4435,  1998,  2944,  1997,  2054,  2001,  1996,
         4435,  1998,  2944,  1997,  1996,  3751,  8040, 17206,  2121,  2008,
         3465,  1002, 15678,  1029,  2020, 21125,  2012,  1002, 15678,  1029,
          102,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 0], device='cuda:0')

ResuTehran0021189196.lts saved to ./Retrieval/Results/A_Multi_colbert_index.jsonl
Retrieving for track A, type Uni, retriever_name colbert

#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Dante buy for $1,450?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106,  9649,  4965,  2005,  1002,  1015,  1010,
        10332,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Alejandro buy for $1,450?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 16810,  4965,  2005,  1002,  1015,  1010,
        10332,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Jin buy for $150?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2106, 9743, 4965, 2005, 1002, 5018, 1029,  102,  103,
         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Ivan buy for $950?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106,  7332,  4965,  2005,  1002, 20317,  1029,
          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Hugo buy for $1,950?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106,  9395,  4965,  2005,  1002,  1015,  1010,
        20317,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Emil buy for $2,550?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 16243,  4965,  2005,  1002,  1016,  1010,
        13274,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Chen buy for $1,850?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106,  8802,  4965,  2005,  1002,  1015,  1010,
        15678,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Thomas buy for $2,250?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2106, 2726, 4965, 2005, 1002, 1016, 1010, 5539, 1029,
         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Bianca buy for $2,250?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 18051,  4965,  2005,  1002,  1016,  1010,
         5539,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Yuri buy for $650?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 14331,  4965,  2005,  1002, 13757,  1029,
          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Mohammed buy for $1,250?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 12619,  4965,  2005,  1002,  1015,  1010,
         5539,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Alicia buy for $550?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 15935,  4965,  2005,  1002, 13274,  1029,
          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Ali buy for $650?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106,  4862,  4965,  2005,  1002, 13757,  1029,
          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Camila buy for $1,750?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 11503, 11733,  4965,  2005,  1002,  1015,
         1010,  9683,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Helen buy for $850?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106,  6330,  4965,  2005,  1002, 15678,  1029,
          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Irina buy for $1,350?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 25404,  4965,  2005,  1002,  1015,  1010,
         8698,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Rose buy for $250?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2106, 3123, 4965, 2005, 1002, 5539, 1029,  102,  103,
         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Alessia buy for $2,250?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 15669, 18719,  2050,  4965,  2005,  1002,
         1016,  1010,  5539,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Victoria buy for $750?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2106, 3848, 4965, 2005, 1002, 9683, 1029,  102,  103,
         103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Hailey buy for $450?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 21664,  4965,  2005,  1002, 10332,  1029,
          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Mila buy for $2,850?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 23689,  2050,  4965,  2005,  1002,  1016,
         1010, 15678,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Henry buy for $1,350?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2106, 2888, 4965, 2005, 1002, 1015, 1010, 8698, 1029,
         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Noor buy for $1,450?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106,  2053,  2953,  4965,  2005,  1002,  1015,
         1010, 10332,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Yuna buy for $1,550?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 22854,  2050,  4965,  2005,  1002,  1015,
         1010, 13274,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Joel buy for $1,750?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2106, 8963, 4965, 2005, 1002, 1015, 1010, 9683, 1029,
         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Adam buy for $1,850?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106,  4205,  4965,  2005,  1002,  1015,  1010,
        15678,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Evan buy for $2,650?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106,  9340,  4965,  2005,  1002,  1016,  1010,
        13757,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Leonardo buy for $2,450?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 14720,  4965,  2005,  1002,  1016,  1010,
        10332,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Ethan buy for $1,950?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106,  6066,  4965,  2005,  1002,  1015,  1010,
        20317,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Heidi buy for $450?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 21372,  4965,  2005,  1002, 10332,  1029,
          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Leah buy for $1,650?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 14188,  4965,  2005,  1002,  1015,  1010,
        13757,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Malik buy for $2,050?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 14360,  4965,  2005,  1002,  1016,  1010,
        28714,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Carmen buy for $1,350?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 11425,  4965,  2005,  1002,  1015,  1010,
         8698,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Logan buy for $1,250?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2106, 6307, 4965, 2005, 1002, 1015, 1010, 5539, 1029,
         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Liam buy for $1,050?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106,  8230,  4965,  2005,  1002,  1015,  1010,
        28714,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Jayden buy for $2,550?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106,  6108,  4181,  4965,  2005,  1002,  1016,
         1010, 13274,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Ananya buy for $2,150?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106,  9617, 17238,  4965,  2005,  1002,  1016,
         1010,  5018,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Owen buy for $850?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106,  7291,  4965,  2005,  1002, 15678,  1029,
          102,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Stella buy for $2,050?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 11894,  4965,  2005,  1002,  1016,  1010,
        28714,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Dominic buy for $1,650?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 11282,  4965,  2005,  1002,  1015,  1010,
        13757,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Makayla buy for $1,850?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106,  5003,  2912, 23943,  4965,  2005,  1002,
         1015,  1010, 15678,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Ayanda buy for $1,150?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2106, 1037, 7054, 2850, 4965, 2005, 1002, 1015, 1010,
        5018, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Tom buy for $1,250?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2106, 3419, 4965, 2005, 1002, 1015, 1010, 5539, 1029,
         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Julia buy for $1,550?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106,  6423,  4965,  2005,  1002,  1015,  1010,
        13274,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Louis buy for $1,050?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106,  3434,  4965,  2005,  1002,  1015,  1010,
        28714,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Xavier buy for $1,050?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 10062,  4965,  2005,  1002,  1015,  1010,
        28714,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Greta buy for $1,550?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 26111,  4965,  2005,  1002,  1015,  1010,
        13274,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Atsuko buy for $50?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2106, 2012, 6342, 3683, 4965, 2005, 1002, 2753, 1029,
         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Andrei buy for $2,350?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 18125,  4965,  2005,  1002,  1016,  1010,
         8698,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What did Imani buy for $1,850?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2106, 10047,  7088,  4965,  2005,  1002,  1015,
         1010, 15678,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')

ResuTehran0021189196.lts saved to ./Retrieval/Results/A_Uni_colbert_index.jsonl
Retrieving for track T, type Multi, retriever_name colbert

#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was reading a leisure book on February 27, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  3752,  1037, 12257,  2338,  2006,  2337,
         2676,  1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was watching a new movie at home on April 26, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  3666,  1037,  2047,  3185,  2012,  2188,
         2006,  2258,  2656,  1010, 16798,  2549,  1029,   102,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was playing a video game on January 25, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  2652,  1037,  2678,  2208,  2006,  2254,
         2423,  1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was cooking a new recipe on March 06, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  8434,  1037,  2047, 17974,  2006,  2233,
         5757,  1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was baking a cake or cookies on February 20, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001, 21522,  1037,  9850,  2030, 16324,  2006,
         2337,  2322,  1010, 16798,  2549,  1029,   102,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was gardening on April 05, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001, 21529,  2006,  2258,  5709,  1010, 16798,
         2549,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was on a nature hike on June 24, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  2006,  1037,  3267, 21857,  2006,  2238,
         2484,  1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was doing yoga or a home workout on February 25, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  2725, 13272,  2030,  1037,  2188, 27090,
         2006,  2337,  2423,  1010, 16798,  2549,  1029,   102,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was journaling on May 31, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  3485,  2075,  2006,  2089,  2861,  1010,
        16798,  2549,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was painting or drawing on January 26, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  4169,  2030,  5059,  2006,  2254,  2656,
         1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was playing a board game or card game on September 01, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  2652,  1037,  2604,  2208,  2030,  4003,
         2208,  2006,  2244,  5890,  1010, 16798,  2549,  1029,   102,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was learning a language online on January 11, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  4083,  1037,  2653,  3784,  2006,  2254,
         2340,  1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was working on a coding project on August 26, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  2551,  2006,  1037, 16861,  2622,  2006,
         2257,  2656,  1010, 16798,  2549,  1029,   102,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was deep cleaning a room on May 08, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  2784,  9344,  1037,  2282,  2006,  2089,
         5511,  1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was doing laundry on March 01, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  2725, 14533,  2006,  2233,  5890,  1010,
        16798,  2549,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was grocery shopping on August 12, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001, 13025,  6023,  2006,  2257,  2260,  1010,
        16798,  2549,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was meditating on September 20, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001, 19960, 16518,  2006,  2244,  2322,  1010,
        16798,  2549,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was on a long phone call on June 01, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  2006,  1037,  2146,  3042,  2655,  2006,
         2238,  5890,  1010, 16798,  2549,  1029,   102,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was on a picnic on February 16, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  2006,  1037, 12695,  2006,  2337,  2385,
         1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was assembling furniture on May 31, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  4632,  6633,  9709,  7390,  2006,  2089,
         2861,  1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was repairing a household item on May 15, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001, 26296,  1037,  4398,  8875,  2006,  2089,
         2321,  1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was organizing a closet or bookshelf on July 22, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001, 10863,  1037,  9346,  2030,  2808, 16001,
         2546,  2006,  2251,  2570,  1010, 16798,  2549,  1029,   102,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was planning a trip itinerary on August 22, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  4041,  1037,  4440,  2009, 26455,  5649,
         2006,  2257,  2570,  1010, 16798,  2549,  1029,   102,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was taking photos outdoors on March 03, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  2635,  7760, 19350,  2006,  2233,  6021,
         1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was birdwatching on March 20, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  4743, 18866,  2075,  2006,  2233,  2322,
         1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was fishing on August 07, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  5645,  2006,  2257,  5718,  1010, 16798,
         2549,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was stargazing on August 14, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  2732,  3654,  6774,  2006,  2257,  2403,
         1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was volunteering on May 25, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  6951,  2075,  2006,  2089,  2423,  1010,
        16798,  2549,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was working on a jigsaw puzzle on July 05, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  2551,  2006,  1037, 10147,  5620, 10376,
        11989,  2006,  2251,  5709,  1010, 16798,  2549,  1029,   102,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was listening to a podcast or album on June 20, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  5962,  2000,  1037, 16110,  2030,  2201,
         2006,  2238,  2322,  1010, 16798,  2549,  1029,   102,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was writing a story or poem on July 17, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  3015,  1037,  2466,  2030,  5961,  2006,
         2251,  2459,  1010, 16798,  2549,  1029,   102,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was practicing an instrument on July 07, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001, 12560,  2019,  6602,  2006,  2251,  5718,
         1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was knitting or crocheting on July 22, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001, 26098,  2030, 13675, 23555,  3436,  2006,
         2251,  2570,  1010, 16798,  2549,  1029,   102,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was on a bike ride on July 28, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  2006,  1037,  7997,  4536,  2006,  2251,
         2654,  1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was mowing the lawn or doing yard work on October 06, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  9587,  9328,  1996, 10168,  2030,  2725,
         4220,  2147,  2006,  2255,  5757,  1010, 16798,  2549,  1029,   102,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was washing their car on May 03, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001, 12699,  2037,  2482,  2006,  2089,  6021,
         1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was brewing beer or kombucha on June 16, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001, 16005,  5404,  2030, 12849, 14905, 10875,
         2050,  2006,  2238,  2385,  1010, 16798,  2549,  1029,   102,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was researching a personal interest online on October 14, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001, 20059,  1037,  3167,  3037,  3784,  2006,
         2255,  2403,  1010, 16798,  2549,  1029,   102,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was upcycling an old item on May 04, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  2039,  5666, 20464,  2075,  2019,  2214,
         8875,  2006,  2089,  5840,  1010, 16798,  2549,  1029,   102,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was building a model kit on August 22, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  2311,  1037,  2944,  8934,  2006,  2257,
         2570,  1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was watching an educational documentary on October 02, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  3666,  2019,  4547,  4516,  2006,  2255,
         6185,  1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was writing a blog post or article on January 17, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  3015,  1037,  9927,  2695,  2030,  3720,
         2006,  2254,  2459,  1010, 16798,  2549,  1029,   102,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was designing digital art on April 29, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001, 12697,  3617,  2396,  2006,  2258,  2756,
         1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was practicing calligraphy or hand-lettering on February 10, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001, 12560,  2655, 23132,  2030,  2192,  1011,
        25782,  2006,  2337,  2184,  1010, 16798,  2549,  1029,   102,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was doing a crossword or Sudoku puzzle on May 31, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  2725,  1037,  2892, 18351,  2030, 19219,
        21940, 11989,  2006,  2089,  2861,  1010, 16798,  2549,  1029,   102,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was taking a long bath on February 19, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  2635,  1037,  2146,  7198,  2006,  2337,
         2539,  1010, 16798,  2549,  1029,   102,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was setting up a new tech gadget on March 24, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  4292,  2039,  1037,  2047,  6627, 11721,
        24291,  2006,  2233,  2484,  1010, 16798,  2549,  1029,   102,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was sorting and donating old items on August 08, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001, 22210,  1998, 24260,  3436,  2214,  5167,
         2006,  2257,  5511,  1010, 16798,  2549,  1029,   102,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was learning a new craft from a tutorial on March 10, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001,  4083,  1037,  2047,  7477,  2013,  1037,
        14924,  4818,  2006,  2233,  2184,  1010, 16798,  2549,  1029,   102,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who was exploring a new neighborhood on foot on February 25, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2001, 11131,  1037,  2047,  5101,  2006,  3329,
         2006,  2337,  2423,  1010, 16798,  2549,  1029,   102,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')

ResuTehran0021189196.lts saved to ./Retrieval/Results/T_Multi_colbert_index.jsonl
Retrieving for track T, type Uni, retriever_name colbert

#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Dante', 'persona': 'Dante is a poet and spoken word artist from Italy, whose work explores themes of identity, love, and social justice. He performs at literary festivals and community events, using his powerful voice to inspire and provoke thought. He believes poetry can be a catalyst for change.'} scheduled to be doing at 16:00 on April 26, 2021?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         9649,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  9649,  2003,
         1037,  4802,  1998,  5287,  2773,  3063,  2013,  3304,  1010,  3005,
         2147,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Alejandro', 'persona': 'Alejandro is a coffee farmer in the highlands of Colombia, dedicated to producing high-quality, ethically sourced coffee beans. He works closely with his local cooperative to improve farming practices and ensure fair prices. He takes immense pride in the rich flavor of his coffee.'} scheduled to be doing at 16:00 on February 09, 2020?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        16810,  1005,  1010,  1005, 16115,  1005,  1024,  1005, 16810,  2003,
         1037,  4157,  7500,  1999,  1996, 11784,  1997,  7379,  1010,  4056,
         2000,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Jin', 'persona': 'Jin is a talented chef who owns a small, popular Korean fusion restaurant in his neighborhood. He loves experimenting with traditional recipes and sourcing local ingredients. Jin is a family man who hopes to pass on his culinary skills to his children.'} scheduled to be doing at 10:00 on October 21, 2022?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         9743,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  9743,  2003,
         1037, 10904, 10026,  2040,  8617,  1037,  2235,  1010,  2759,  4759,
        10077,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Ivan', 'persona': 'Ivan is a chess grandmaster from Russia, known for his strategic brilliance and calm demeanor during high-stakes matches. He has competed in world championships and now coaches promising young players. He sees chess as a beautiful art form as well as a sport.'} scheduled to be doing at 10:00 on August 01, 2022?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         7332,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  7332,  2003,
         1037,  7433, 27101,  2013,  3607,  1010,  2124,  2005,  2010,  6143,
        28850,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Hugo', 'persona': 'Hugo is a documentary filmmaker from France, who travels to remote corners of the world to tell stories about unique cultures and environmental challenges. He believes in the power of film to foster empathy and understanding. His work often involves living with communities for extended periods.'} scheduled to be doing at 18:00 on April 20, 2022?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         9395,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  9395,  2003,
         1037,  4516, 12127,  2013,  2605,  1010,  2040,  7930,  2000,  6556,
         8413,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Emil', 'persona': 'Emil is a watchmaker from Switzerland, meticulously crafting and repairing intricate mechanical timepieces. He apprenticed under a master watchmaker and values precision and tradition in his craft. He enjoys collecting vintage watches and studying their complex mechanisms.'} scheduled to be doing at 8:00 on July 08, 2021?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        16243,  1005,  1010,  1005, 16115,  1005,  1024,  1005, 16243,  2003,
         1037,  3422,  8571,  2013,  5288,  1010,  2777,  2594, 21227,  7477,
         2075,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Chen', 'persona': 'Chen is a tea master from China, upholding the ancient traditions of the Chinese tea ceremony. He owns a serene teahouse where he educates guests on the nuances of different teas and their preparation. He believes tea cultivation and appreciation are profound art forms.'} scheduled to be doing at 18:00 on March 18, 2021?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         8802,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  8802,  2003,
         1037,  5572,  3040,  2013,  2859,  1010, 27329,  2075,  1996,  3418,
         7443,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Thomas', 'persona': 'Thomas is a master carpenter from Germany, specializing in restoring historic timber-framed houses. He uses traditional tools and techniques to preserve architectural heritage. He has a deep respect for the craftsmanship of past generations.'} scheduled to be doing at 8:00 on May 17, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         2726,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  2726,  2003,
         1037,  3040, 10533,  2013,  2762,  1010, 14055,  1999, 16487,  3181,
         7227,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Bianca', 'persona': "Bianca is a sommelier at a Michelin-starred restaurant in Italy, with an encyclopedic knowledge of Italian wines. She expertly pairs wines with the chef's exquisite dishes and enjoys educating guests about different varietals. She frequently visits vineyards to discover new wines."} scheduled to be doing at 17:00 on December 04, 2020?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        18051,  1005,  1010,  1005, 16115,  1005,  1024,  1000, 18051,  2003,
         1037, 25158, 14355,  2012,  1037,  8709,  2378,  1011,  5652,  4825,
         1999,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Yuri', 'persona': 'Yuri is a cosmonaut from Russia, who has spent months aboard the International Space Station conducting scientific experiments. He is fascinated by space exploration and the challenges of living in microgravity. He enjoys sharing his experiences with students and the public.'} scheduled to be doing at 17:00 on November 09, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        14331,  1005,  1010,  1005, 16115,  1005,  1024,  1005, 14331,  2003,
         1037,  2522, 25855, 24619,  2013,  3607,  1010,  2040,  2038,  2985,
         2706,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Mohammed', 'persona': 'Mohammed is a calligrapher from Saudi Arabia, skilled in various forms of Islamic calligraphy. He creates intricate artworks for mosques, exhibitions, and private collectors. He sees his art as a spiritual practice and a way to beautify sacred texts.'} scheduled to be doing at 18:00 on November 24, 2023?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        12619,  1005,  1010,  1005, 16115,  1005,  1024,  1005, 12619,  2003,
         1037,  2655,  8004, 24342,  2121,  2013,  8174,  9264,  1010, 10571,
         1999,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Alicia', 'persona': "Alicia is a pediatric nurse in a bustling city hospital, known for her compassionate care and ability to comfort sick children. She works long hours but finds immense fulfillment in helping young patients and their families. She volunteers at a children's charity in her spare time."} scheduled to be doing at 17:00 on June 09, 2020?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        15935,  1005,  1010,  1005, 16115,  1005,  1024,  1000, 15935,  2003,
         1037, 23614,  6821,  1999,  1037, 13950,  2989,  2103,  2902,  1010,
         2124,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Ali', 'persona': 'Ali is a traditional oud player and composer from Syria, now living in exile. His music blends mournful melodies with hopeful rhythms, reflecting his experiences and cultural heritage. He performs internationally, sharing the rich musical traditions of his homeland.'} scheduled to be doing at 17:00 on April 21, 2020?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         4862,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  4862,  2003,
         1037,  3151, 15068,  2094,  2447,  1998,  4543,  2013,  7795,  1010,
         2085,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Camila', 'persona': 'Camila is a muralist from Mexico City, whose vibrant artwork adorns public spaces and galleries, often reflecting social justice themes. She draws inspiration from Mexican folklore and contemporary urban life. She believes art can be a powerful tool for community engagement and change.'} scheduled to be doing at 18:00 on January 03, 2021?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        11503, 11733,  1005,  1010,  1005, 16115,  1005,  1024,  1005, 11503,
        11733,  2003,  1037, 15533,  2923,  2013,  3290,  2103,  1010,  3005,
        17026,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Helen', 'persona': 'Helen is a classical historian from Greece, specializing in ancient Athenian democracy and philosophy. She teaches at the University of Athens and leads archaeological tours of the Acropolis. She is passionate about bringing the ancient world to life for her students.'} scheduled to be doing at 10:00 on February 08, 2022?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         6330,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  6330,  2003,
         1037,  4556,  5272,  2013,  5483,  1010, 14055,  1999,  3418, 26956,
         7072,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Irina', 'persona': 'Irina is a rhythmic gymnast from Belarus, known for her flexibility, grace, and expressive routines with ribbon, hoop, and ball. She trains rigorously and competes in international competitions, aiming for Olympic gold. She enjoys choreographing her own routines.'} scheduled to be doing at 18:00 on July 01, 2022?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        25404,  1005,  1010,  1005, 16115,  1005,  1024,  1005, 25404,  2003,
         1037, 14797, 25055,  2013, 12545,  1010,  2124,  2005,  2014, 16991,
         1010,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Rose', 'persona': 'Rose is a vintage clothing store owner from the USA, with a flair for curating unique and timeless pieces. She travels extensively to source her collection and has a deep knowledge of fashion history. Her shop is a beloved destination for fashion enthusiasts.'} scheduled to be doing at 16:00 on March 08, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         3123,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  3123,  2003,
         1037, 13528,  5929,  3573,  3954,  2013,  1996,  3915,  1010,  2007,
         1037,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Alessia', 'persona': 'Alessia is an opera singer from Milan, Italy, whose powerful soprano voice captivates audiences in renowned opera houses. She has performed leading roles in classic operas and enjoys the challenge of contemporary compositions. She is dedicated to the art of bel canto.'} scheduled to be doing at 9:00 on March 21, 2020?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        15669, 18719,  2050,  1005,  1010,  1005, 16115,  1005,  1024,  1005,
        15669, 18719,  2050,  2003,  2019,  3850,  3220,  2013,  6954,  1010,
         3304,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Victoria', 'persona': 'Victoria is a museum curator in London, UK, specializing in 19th-century art and artifacts. She meticulously researches and designs exhibitions that bring history to life for visitors. She enjoys visiting historical sites and antique shops in her free time.'} scheduled to be doing at 18:00 on July 28, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         3848,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  3848,  2003,
         1037,  2688, 13023,  1999,  2414,  1010,  2866,  1010, 14055,  1999,
         3708,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Hailey', 'persona': 'Hailey is a professional snowboarder from Canada, competing in slopestyle and big air events worldwide. She is known for her daring tricks and stylish riding. She spends her winters training and competing, and her summers hiking and mountain biking.'} scheduled to be doing at 17:00 on November 23, 2021?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        21664,  1005,  1010,  1005, 16115,  1005,  1024,  1005, 21664,  2003,
         1037,  2658,  4586,  6277,  2121,  2013,  2710,  1010,  6637,  1999,
        10314,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Mila', 'persona': 'Mila is a foreign correspondent from Serbia, reporting from conflict zones and areas affected by humanitarian crises. Her work is often dangerous, but she is committed to bearing witness and telling important global stories. She believes in the power of journalism to inform and inspire change.'} scheduled to be doing at 8:00 on October 14, 2023?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        23689,  2050,  1005,  1010,  1005, 16115,  1005,  1024,  1005, 23689,
         2050,  2003,  1037,  3097, 11370,  2013,  7238,  1010,  7316,  2013,
         4736,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Henry', 'persona': 'Henry is a vintage car restorer from the USA, who brings classic automobiles back to their former glory. He has a deep knowledge of automotive history and mechanics. He enjoys attending car shows and cruising in his restored vehicles on scenic routes.'} scheduled to be doing at 10:00 on March 19, 2022?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         2888,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  2888,  2003,
         1037, 13528,  2482,  9239,  2099,  2013,  1996,  3915,  1010,  2040,
         7545,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Noor', 'persona': "Noor is a social worker in Amman, Jordan, committed to supporting underprivileged families and children. She organizes community workshops and provides counseling services. She finds her work challenging but immensely rewarding, making a tangible difference in people's lives."} scheduled to be doing at 10:00 on December 17, 2023?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         2053,  2953,  1005,  1010,  1005, 16115,  1005,  1024,  1000,  2053,
         2953,  2003,  1037,  2591,  7309,  1999, 25703,  1010,  5207,  1010,
         5462,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Yuna', 'persona': 'Yuna is a kindergarten teacher in Busan, South Korea, adored by her young students for her creativity and warmth. She enjoys crafting and storytelling, incorporating both into her teaching methods. She believes in nurturing a love for learning from an early age.'} scheduled to be doing at 10:00 on October 05, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        22854,  2050,  1005,  1010,  1005, 16115,  1005,  1024,  1005, 22854,
         2050,  2003,  1037, 11793,  3836,  1999,  3902,  2319,  1010,  2148,
         4420,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Joel', 'persona': 'Joel is a wildlife filmmaker from Australia, traveling to remote corners of the globe to document animal behavior and ecosystems. He is passionate about conservation and uses his films to raise awareness about endangered species. He is an expert scuba diver and often films underwater.'} scheduled to be doing at 18:00 on November 18, 2022?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         8963,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  8963,  2003,
         1037,  6870, 12127,  2013,  2660,  1010,  7118,  2000,  6556,  8413,
         1997,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Adam', 'persona': 'Adam is a software engineer at a leading tech company in Silicon Valley, specializing in artificial intelligence. He is constantly learning new programming languages and enjoys tackling complex algorithmic challenges. He hopes to develop AI that can solve significant global problems.'} scheduled to be doing at 18:00 on January 14, 2020?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         4205,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  4205,  2003,
         1037,  4007,  3992,  2012,  1037,  2877,  6627,  2194,  1999, 13773,
         3028,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Evan', 'persona': 'Evan is a jazz pianist from Chicago, known for his improvisational skills and deep understanding of jazz harmony. He leads his own trio and performs regularly at jazz clubs and festivals. He also composes original music that blends traditional jazz with contemporary influences.'} scheduled to be doing at 8:00 on September 09, 2021?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         9340,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  9340,  2003,
         1037,  4166,  9066,  2013,  3190,  1010,  2124,  2005,  2010, 24584,
         2389,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Leonardo', 'persona': 'Leonardo is a sculptor from Italy, working primarily with marble and bronze in his Florence studio. He draws inspiration from classical art and mythology, creating powerful and expressive figures. His studio is filled with sketches, models, and works in progress.'} scheduled to be doing at 9:00 on March 08, 2023?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        14720,  1005,  1010,  1005, 16115,  1005,  1024,  1005, 14720,  2003,
         1037, 10160,  2013,  3304,  1010,  2551,  3952,  2007,  7720,  1998,
         4421,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Ethan', 'persona': 'Ethan is a video game developer from the USA, focused on creating immersive virtual reality experiences. He is passionate about the intersection of technology and storytelling, constantly experimenting with new VR hardware and software. He dreams of creating a truly groundbreaking VR game.'} scheduled to be doing at 18:00 on August 08, 2021?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         6066,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  6066,  2003,
         1037,  2678,  2208,  9722,  2013,  1996,  3915,  1010,  4208,  2006,
         4526,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Heidi', 'persona': 'Heidi is an alpine skier from Austria, competing in downhill and slalom events on the World Cup circuit. She grew up in the mountains and has been skiing since she could walk. She is known for her fearless speed and technical precision.'} scheduled to be doing at 9:00 on January 07, 2022?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        21372,  1005,  1010,  1005, 16115,  1005,  1024,  1005, 21372,  2003,
         2019, 10348, 21294,  2013,  5118,  1010,  6637,  1999, 19448,  1998,
        19617,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Leah', 'persona': 'Leah is a glassblower from the Czech Republic, creating delicate and colorful art glass pieces. Her studio is a hive of heat and activity as she shapes molten glass with skill and precision. Her work is exhibited in galleries and sought after by collectors.'} scheduled to be doing at 17:00 on January 25, 2023?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        14188,  1005,  1010,  1005, 16115,  1005,  1024,  1005, 14188,  2003,
         1037,  3221, 16558, 25114,  2013,  1996,  5569,  3072,  1010,  4526,
        10059,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Malik', 'persona': 'Malik is a software developer from Jordan, creating mobile apps that focus on education and accessibility. He is passionate about using technology to bridge learning gaps. He volunteers his weekends teaching coding to underprivileged youth.'} scheduled to be doing at 18:00 on September 07, 2023?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        14360,  1005,  1010,  1005, 16115,  1005,  1024,  1005, 14360,  2003,
         1037,  4007,  9722,  2013,  5207,  1010,  4526,  4684, 18726,  2008,
         3579,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Carmen', 'persona': "Carmen is a librarian from Spain, passionate about promoting literacy and fostering a love of reading in her community. She organizes author talks, children's story hours, and book clubs. She believes libraries are vital spaces for learning and connection."} scheduled to be doing at 8:00 on February 09, 2021?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        11425,  1005,  1010,  1005, 16115,  1005,  1024,  1000, 11425,  2003,
         1037, 13850,  2013,  3577,  1010, 13459,  2055,  7694,  8433,  1998,
         6469,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Logan', 'persona': 'Logan is a wilderness guide from Alaska, leading trekking and kayaking expeditions in remote natural areas. They are an expert in survival skills and passionate about environmental conservation. They feel most at home in the great outdoors, exploring untouched landscapes.'} scheduled to be doing at 17:00 on May 16, 2023?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         6307,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  6307,  2003,
         1037,  9917,  5009,  2013,  7397,  1010,  2877, 10313,  6834,  1998,
        10905,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Liam', 'persona': 'Liam is a software engineer from Ireland, living in a bustling city and known for his analytical mind. In his free time, he enjoys competitive gaming and exploring new coding languages. He dreams of launching his own tech startup focused on sustainable energy solutions.'} scheduled to be doing at 9:00 on April 18, 2023?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         8230,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  8230,  2003,
         1037,  4007,  3992,  2013,  3163,  1010,  2542,  1999,  1037, 13950,
         2989,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Jayden', 'persona': 'Jayden is a competitive eSports player from South Korea, specializing in a popular strategy game. They train for many hours a day, honing their skills and teamwork with their professional team. They dream of winning the world championship.'} scheduled to be doing at 10:00 on September 17, 2022?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         6108,  4181,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  6108,
         4181,  2003,  1037,  6975,  9686, 25378,  2447,  2013,  2148,  4420,
         1010,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Ananya', 'persona': 'Ananya is a fashion designer from India, known for her sustainable and ethically produced clothing line. She blends traditional Indian textiles with contemporary silhouettes, creating unique and elegant garments. She is a strong advocate for fair trade in the fashion industry.'} scheduled to be doing at 17:00 on July 15, 2020?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         9617, 17238,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  9617,
        17238,  2003,  1037,  4827,  5859,  2013,  2634,  1010,  2124,  2005,
         2014,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Owen', 'persona': 'Owen is a blacksmith from Wales, forging traditional ironwork using techniques passed down through generations. His workshop is filled with the clang of the hammer and the heat of the forge. He creates everything from ornate gates to custom tools, valuing craftsmanship and durability.'} scheduled to be doing at 10:00 on January 27, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         7291,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  7291,  2003,
         1037, 20987,  2013,  3575,  1010,  2005,  4726,  3151,  3707,  6198,
         2478,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Stella', 'persona': 'Stella is a jazz singer from the USA, with a smoky voice and captivating stage presence, performing regularly in intimate New York City clubs. She interprets classic jazz standards with her unique style and also writes her own compositions. She loves the improvisational and collaborative nature of jazz.'} scheduled to be doing at 16:00 on April 06, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        11894,  1005,  1010,  1005, 16115,  1005,  1024,  1005, 11894,  2003,
         1037,  4166,  3220,  2013,  1996,  3915,  1010,  2007,  1037, 20629,
         2376,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Dominic', 'persona': 'Dominic is a master craftsman from Ireland, specializing in traditional boat building using wood. He learned the trade from his father and creates beautiful, sturdy currachs and other vessels. He values the heritage and artistry of his craft.'} scheduled to be doing at 9:00 on June 02, 2021?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        11282,  1005,  1010,  1005, 16115,  1005,  1024,  1005, 11282,  2003,
         1037,  3040, 26286,  2013,  3163,  1010, 14055,  1999,  3151,  4049,
         2311,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Makayla', 'persona': 'Makayla is a gymnast from the USA, training for the Olympic Games. Her dedication and talent in floor exercises and balance beam are remarkable. She spends most of her days perfecting routines and building strength.'} scheduled to be doing at 17:00 on July 26, 2023?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         5003,  2912, 23943,  1005,  1010,  1005, 16115,  1005,  1024,  1005,
         5003,  2912, 23943,  2003,  1037, 25055,  2013,  1996,  3915,  1010,
         2731,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Ayanda', 'persona': 'Ayanda is a playwright and theater director from South Africa, whose works explore post-apartheid identity and social issues. Her plays are known for their sharp dialogue and powerful performances. She is committed to fostering a vibrant and inclusive local theater scene.'} scheduled to be doing at 17:00 on October 26, 2020?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         1037,  7054,  2850,  1005,  1010,  1005, 16115,  1005,  1024,  1005,
         1037,  7054,  2850,  2003,  1037, 11170,  1998,  4258,  2472,  2013,
         2148,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Tom', 'persona': 'Tom is a craftsman from the USA, who makes bespoke leather goods by hand, from wallets to briefcases. He uses traditional tools and techniques, valuing quality and durability. His workshop smells of leather and beeswax, a testament to his dedication to his art.'} scheduled to be doing at 17:00 on June 23, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         3419,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  3419,  2003,
         1037, 26286,  2013,  1996,  3915,  1010,  2040,  3084,  2022, 13102,
        11045,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Julia', 'persona': 'Julia is a forensic scientist from Brazil, who works with law enforcement to solve complex crimes. She is meticulous in her analysis of evidence and dedicated to finding the truth. She unwinds by reading mystery novels and practicing kickboxing.'} scheduled to be doing at 10:00 on December 25, 2022?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         6423,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  6423,  2003,
         1037, 15359,  7155,  2013,  4380,  1010,  2040,  2573,  2007,  2375,
         7285,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Louis', 'persona': 'Louis is a Michelin-starred chef from France, known for his avant-garde approach to French cuisine. He constantly experiments with new techniques and flavor combinations. His restaurant is a destination for culinary adventurers seeking a unique dining experience.'} scheduled to be doing at 16:00 on June 23, 2023?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         3434,  1005,  1010,  1005, 16115,  1005,  1024,  1005,  3434,  2003,
         1037,  8709,  2378,  1011,  5652, 10026,  2013,  2605,  1010,  2124,
         2005,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Xavier', 'persona': "Xavier is a jazz trumpeter from New Orleans, USA, known for his soulful improvisations and deep connection to the city's musical heritage. He leads his own band and performs regularly at historic jazz venues. He also mentors young musicians in his community."} scheduled to be doing at 16:00 on August 27, 2024?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        10062,  1005,  1010,  1005, 16115,  1005,  1024,  1000, 10062,  2003,
         1037,  4166, 28220,  2013,  2047,  5979,  1010,  3915,  1010,  2124,
         2005,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Greta', 'persona': 'Greta is an environmental scientist from Germany, researching the impacts of microplastics on marine ecosystems. She conducts lab experiments and fieldwork, advocating for policies to reduce plastic pollution. She is passionate about protecting the health of our oceans.'} scheduled to be doing at 18:00 on October 27, 2021?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        26111,  1005,  1010,  1005, 16115,  1005,  1024,  1005, 26111,  2003,
         2019,  4483,  7155,  2013,  2762,  1010, 20059,  1996, 14670,  1997,
        12702,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Atsuko', 'persona': 'Atsuko is a manga artist from Japan, known for her intricate character designs and compelling storylines in the shojo genre. She works long hours to meet deadlines but finds immense satisfaction in seeing her creations come to life. Her manga series has a dedicated international fanbase.'} scheduled to be doing at 17:00 on September 20, 2020?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
         2012,  6342,  3683,  1005,  1010,  1005, 16115,  1005,  1024,  1005,
         2012,  6342,  3683,  2003,  1037,  8952,  3063,  2013,  2900,  1010,
         2124,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Andrei', 'persona': 'Andrei is a classical violinist from Romania, performing as a soloist with major orchestras around the world. He began playing at a young age and is celebrated for his technical brilliance and emotive interpretations. He also enjoys teaching masterclasses to aspiring musicians.'} scheduled to be doing at 17:00 on August 19, 2020?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        18125,  1005,  1010,  1005, 16115,  1005,  1024,  1005, 18125,  2003,
         1037,  4556, 16609,  2013,  6339,  1010,  4488,  2004,  1037, 16504,
         2007,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was {'name': 'Imani', 'persona': 'Imani is a community health worker from Tanzania, providing essential healthcare services and education in a rural village. She travels long distances to reach remote households and is dedicated to improving the well-being of her community. She finds her work deeply fulfilling.'} scheduled to be doing at 16:00 on May 21, 2022?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  1063,  1005,  2171,  1005,  1024,  1005,
        10047,  7088,  1005,  1010,  1005, 16115,  1005,  1024,  1005, 10047,
         7088,  2003,  1037,  2451,  2740,  7309,  2013, 11959,  1010,  4346,
         6827,   102], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')

ResuTehran0021189196.lts saved to ./Retrieval/Results/T_Uni_colbert_index.jsonl
Retrieving for track S, type Multi, retriever_name colbert

#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a community skills workshop in United Kingdom?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 2451, 4813, 8395, 1999, 2142,
        2983, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a public lecture series in Canada?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 2270, 8835, 2186, 1999, 2710,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a local art exhibition opening in Thailand?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 2334, 2396, 4538, 3098, 1999,
        6504, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a charity fun run in Finland?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 5952, 4569, 2448, 1999, 6435,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in an open mic night in Libya?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  2019,  2330, 23025,  2305,
         1999, 12917,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a board game meetup in Philippines?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 2604, 2208, 3113, 6279, 1999,
        5137, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a community potluck dinner in Bulgaria?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 2451, 8962, 7630, 3600, 4596,
        1999, 8063, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in an amateur theatre production in Libya?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  2019,  5515,  3004,  2537,
         1999, 12917,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a guest speaker forum in Finland?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 4113, 5882, 7057, 1999, 6435,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in an independent film screening in Germany?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  2019,  2981,  2143, 11326,
         1999,  2762,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in an artisan craft fair in India?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  2019,  2396, 29196,  7477,
         4189,  1999,  2634,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a community volunteer day in Spain?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 2451, 6951, 2154, 1999, 3577,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a public book club meeting in Austria?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 2270, 2338, 2252, 3116, 1999,
        5118, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a weekend farmers market in Ukraine?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 5353, 6617, 3006, 1999, 5924,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a local band showcase in Chile?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  1037,  2334,  2316, 13398,
         1999,  7029,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a pub trivia competition in Poland?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  1037,  9047, 13012,  9035,
         2971,  1999,  3735,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a beginners dance workshop in United Arab Emirates?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  1037,  4088, 16912,  3153,
         8395,  1999,  2142,  5424, 14041,  1029,   102,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a group cooking class in New Zealand?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 2177, 8434, 2465, 1999, 2047,
        3414, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a tech innovators meetup in France?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 6627, 7601, 7103, 6591, 3113,
        6279, 1999, 2605, 1029,  102,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a regional career fair in Australia?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 3164, 2476, 4189, 1999, 2660,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a community wellness expo in Tanzania?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  1037,  2451, 25860, 16258,
         1999, 11959,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a live storytelling night in France?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  1037,  2444, 20957,  2305,
         1999,  2605,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a civic issues debate in Tanzania?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  1037,  8388,  3314,  5981,
         1999, 11959,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in an urban gardening exchange in Thailand?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  2019,  3923, 21529,  3863,
         1999,  6504,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a guided photography walk in Bulgaria?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 8546, 5855, 3328, 1999, 8063,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a local history talk in South Korea?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 2334, 2381, 2831, 1999, 2148,
        4420, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a charity bake sale in Ireland?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 5952, 8670, 3489, 5096, 1999,
        3163, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a DIY electronics workshop in Romania?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 4487, 2100, 8139, 8395, 1999,
        6339, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in an improv comedy show in Kosovo?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  2019, 17727, 12298,  4038,
         2265,  1999, 11491,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a language exchange cafe in Canada?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 2653, 3863, 7668, 1999, 2710,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a group mindfulness session in Argentina?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  1037,  2177,  2568, 20938,
         5219,  1999,  5619,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a community choir concert in Brazil?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 2451, 6596, 4164, 1999, 4380,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a neighborhood repair clinic in Turkey?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 5101, 7192, 9349, 1999, 4977,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a public science forum in Austria?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 2270, 2671, 7057, 1999, 5118,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a vintage collectibles fair in Poland?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  1037, 13528,  8145,  7028,
         2015,  4189,  1999,  3735,  1029,   102,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a family puppet theatre in Chile?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  1037,  2155, 13997,  3004,
         1999,  7029,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a spoken word poetry slam in Australia?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 5287, 2773, 4623, 9555, 1999,
        2660, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in an outdoor group yoga in Norway?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  2019,  7254,  2177, 13272,
         1999,  5120,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a weekend hackathon challenge in United Kingdom?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  1037,  5353, 20578,  8988,
         2239,  4119,  1999,  2142,  2983,  1029,   102,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a tabletop role-playing game night in Bulgaria?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  1037, 13855,  7361,  2535,
         1011,  2652,  2208,  2305,  1999,  8063,  1029,   102,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a community talent showcase in Hungary?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  1037,  2451,  5848, 13398,
         1999,  5872,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a silent headphone disco in United Kingdom?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  1037,  4333,  2132,  9864,
        12532,  1999,  2142,  2983,  1029,   102,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a job seeker resume clinic in Tunisia?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  1037,  3105, 29444, 13746,
         9349,  1999, 13437,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a personal finance seminar in Nigeria?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  1037,  3167,  5446, 18014,
         1999,  7387,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a new parents support group in Ukraine?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 2047, 3008, 2490, 2177, 1999,
        5924, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a public stargazing event in Libya?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  1037,  2270,  2732,  3654,
         6774,  2724,  1999, 12917,  1029,   102,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a community clothing exchange in Denmark?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 1037, 2451, 5929, 3863, 1999, 5842,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a documentary film night in Bosnia and Herzegovina?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  1037,  4516,  2143,  2305,
         1999,  9562,  1998, 11453,  1029,   102,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in an interfaith community dialogue in Brazil?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2040, 2038, 4194, 1999, 2019, 6970, 7011, 8939, 2451, 7982,
        1999, 4380, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: Who has participated in a professional speed networking in Armenia?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2038,  4194,  1999,  1037,  2658,  3177, 14048,
         1999, 10110,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')

ResuTehran0021189196.lts saved to ./Retrieval/Results/F_Multi_colbert_index.jsonl
Retrieving for track S, type Uni, retriever_name colbert

#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Dante's reason for visiting Germany?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 9649, 1005, 1055, 3114, 2005, 5873, 2762, 1029,
         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Alejandro's reason for visiting Chile?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 16810,  1005,  1055,  3114,  2005,  5873,
         7029,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Jin's reason for visiting Uganda?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  9743,  1005,  1055,  3114,  2005,  5873,
        10031,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Ivan's reason for visiting United Kingdom?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 7332, 1005, 1055, 3114, 2005, 5873, 2142, 2983,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Hugo's reason for visiting Belgium?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 9395, 1005, 1055, 3114, 2005, 5873, 5706, 1029,
         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Emil's reason for visiting Indonesia?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 16243,  1005,  1055,  3114,  2005,  5873,
         6239,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Chen's reason for visiting Kosovo?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  8802,  1005,  1055,  3114,  2005,  5873,
        11491,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Thomas's reason for visiting Kenya?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 2726, 1005, 1055, 3114, 2005, 5873, 7938, 1029,
         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Bianca's reason for visiting South Korea?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 18051,  1005,  1055,  3114,  2005,  5873,
         2148,  4420,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Yuri's reason for visiting Ireland?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 14331,  1005,  1055,  3114,  2005,  5873,
         3163,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Mohammed's reason for visiting Uganda?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 12619,  1005,  1055,  3114,  2005,  5873,
        10031,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Alicia's reason for visiting Canada?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 15935,  1005,  1055,  3114,  2005,  5873,
         2710,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Ali's reason for visiting Argentina?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 4862, 1005, 1055, 3114, 2005, 5873, 5619, 1029,
         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Camila's reason for visiting South Africa?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 11503, 11733,  1005,  1055,  3114,  2005,
         5873,  2148,  3088,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Helen's reason for visiting South Africa?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 6330, 1005, 1055, 3114, 2005, 5873, 2148, 3088,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Irina's reason for visiting Denmark?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 25404,  1005,  1055,  3114,  2005,  5873,
         5842,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Rose's reason for visiting Philippines?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 3123, 1005, 1055, 3114, 2005, 5873, 5137, 1029,
         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Alessia's reason for visiting Sudan?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 15669, 18719,  2050,  1005,  1055,  3114,
         2005,  5873, 10411,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Victoria's reason for visiting United States?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 3848, 1005, 1055, 3114, 2005, 5873, 2142, 2163,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Hailey's reason for visiting Kenya?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 21664,  1005,  1055,  3114,  2005,  5873,
         7938,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Mila's reason for visiting France?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 23689,  2050,  1005,  1055,  3114,  2005,
         5873,  2605,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Henry's reason for visiting United Arab Emirates?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  2888,  1005,  1055,  3114,  2005,  5873,
         2142,  5424, 14041,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Noor's reason for visiting Japan?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 2053, 2953, 1005, 1055, 3114, 2005, 5873, 2900,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Yuna's reason for visiting United Kingdom?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 22854,  2050,  1005,  1055,  3114,  2005,
         5873,  2142,  2983,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Joel's reason for visiting Germany?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 8963, 1005, 1055, 3114, 2005, 5873, 2762, 1029,
         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Adam's reason for visiting Cuba?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 4205, 1005, 1055, 3114, 2005, 5873, 7394, 1029,
         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Evan's reason for visiting Tanzania?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  9340,  1005,  1055,  3114,  2005,  5873,
        11959,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Leonardo's reason for visiting Kosovo?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 14720,  1005,  1055,  3114,  2005,  5873,
        11491,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Ethan's reason for visiting Romania?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 6066, 1005, 1055, 3114, 2005, 5873, 6339, 1029,
         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Heidi's reason for visiting Finland?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 21372,  1005,  1055,  3114,  2005,  5873,
         6435,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Leah's reason for visiting Sudan?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 14188,  1005,  1055,  3114,  2005,  5873,
        10411,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Malik's reason for visiting Belgium?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 14360,  1005,  1055,  3114,  2005,  5873,
         5706,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Carmen's reason for visiting Canada?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 11425,  1005,  1055,  3114,  2005,  5873,
         2710,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Logan's reason for visiting United Kingdom?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 6307, 1005, 1055, 3114, 2005, 5873, 2142, 2983,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Liam's reason for visiting Argentina?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 8230, 1005, 1055, 3114, 2005, 5873, 5619, 1029,
         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Jayden's reason for visiting Finland?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 6108, 4181, 1005, 1055, 3114, 2005, 5873, 6435,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Ananya's reason for visiting Russia?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  9617, 17238,  1005,  1055,  3114,  2005,
         5873,  3607,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Owen's reason for visiting Norway?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 7291, 1005, 1055, 3114, 2005, 5873, 5120, 1029,
         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Stella's reason for visiting South Korea?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 11894,  1005,  1055,  3114,  2005,  5873,
         2148,  4420,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Dominic's reason for visiting Russia?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 11282,  1005,  1055,  3114,  2005,  5873,
         3607,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Makayla's reason for visiting Romania?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001,  5003,  2912, 23943,  1005,  1055,  3114,
         2005,  5873,  6339,  1029,   102,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Ayanda's reason for visiting New Zealand?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 1037, 7054, 2850, 1005, 1055, 3114, 2005, 5873,
        2047, 3414, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Tom's reason for visiting Ireland?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 3419, 1005, 1055, 3114, 2005, 5873, 3163, 1029,
         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Julia's reason for visiting United Kingdom?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 6423, 1005, 1055, 3114, 2005, 5873, 2142, 2983,
        1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Louis's reason for visiting Bulgaria?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 3434, 1005, 1055, 3114, 2005, 5873, 8063, 1029,
         102,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Xavier's reason for visiting Finland?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 10062,  1005,  1055,  3114,  2005,  5873,
         6435,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Greta's reason for visiting Sweden?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 26111,  1005,  1055,  3114,  2005,  5873,
         4701,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Atsuko's reason for visiting Denmark?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([ 101,    1, 2054, 2001, 2012, 6342, 3683, 1005, 1055, 3114, 2005, 5873,
        5842, 1029,  102,  103,  103,  103,  103,  103,  103,  103,  103,  103,
         103,  103,  103,  103,  103,  103,  103,  103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Andrei's reason for visiting Ukraine?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 18125,  1005,  1055,  3114,  2005,  5873,
         5924,  1029,   102,   103,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')


#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==
#> Input: What was Imani's reason for visiting Norway?, 		 True, 		 None
#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2001, 10047,  7088,  1005,  1055,  3114,  2005,
         5873,  5120,  1029,   102,   103,   103,   103,   103,   103,   103,
          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,
          103,   103], device='cuda:0')
#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')

ResuTehran0021189196.lts saved to ./Retrieval/Results/F_Uni_colbert_index.jsonl
