{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mounts/Users/cisintern/zeinabtaghavi/MetatagIndexing_2/Dataset_Generation/GeneratingCodes/S_Uni\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import random\n",
    "\n",
    "with open(\"../../Dataset_Helping/names.txt\", \"r\") as file:\n",
    "    names = ' '.join([line.strip() for line in file.readlines()])\n",
    "    names_list = sorted(list(ast.literal_eval(names)))\n",
    "\n",
    "# Load the shopping data from the JSON file.\n",
    "# The file should have the structure as you described.\n",
    "with open(\"../../Dataset_Helping/S_Both/Wikidata_Final.jsonl\", \"r\") as f:\n",
    "    wikidata_samples = [json.loads(line) for line in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# untill you keep the country as a label\n",
    "for sample in wikidata_samples:\n",
    "    if 'country' not in sample.keys():\n",
    "        country = sample['label'].split('-')[-1].strip()\n",
    "        sample['country'] = country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item': 'Nkrumah University',\n",
       " 'label': 'Kabwe - Zambia',\n",
       " 'score': 0.17619562149047852,\n",
       " 'c4_count': 8527,\n",
       " 'country': 'Zambia'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidata_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_user_trip_destination(country_list, num_items):\n",
    "    country_list_names = sorted(list(country_list.keys()))\n",
    "    country_list_names = random.sample(country_list_names, num_items)\n",
    "    user_trip_destinations = []\n",
    "    for country in country_list_names:\n",
    "        user_trip_destinations.append(random.choice(country_list[country]))\n",
    "\n",
    "    return user_trip_destinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "user_num = 50\n",
    "num_items = 30\n",
    "\n",
    "users = random.sample(names_list, user_num)\n",
    "\n",
    "country_list = {}\n",
    "for sample in wikidata_samples:\n",
    "    if sample['country'] not in country_list.keys():\n",
    "        country_list[sample['country']] = [sample]\n",
    "    else:\n",
    "        country_list[sample['country']].append(sample)\n",
    "\n",
    "user_dataset = {}\n",
    "\n",
    "for user in users:\n",
    "    user_dataset[user] = {\"user\": user, \"trip_info\": []}\n",
    "\n",
    "    user_trips_items = generate_user_trip_destination(country_list, num_items)\n",
    "\n",
    "    friends = random.sample([f for f in names_list if f != user], int(num_items * 2))\n",
    "    users_2 = random.sample(friends,num_items)\n",
    "    trip_friends = [f for f in friends if f not in users_2]\n",
    "    for i in range(num_items):\n",
    "        user_2 = users_2[i]\n",
    "        trip = user_trips_items[i]\n",
    "        trip_friend = trip_friends[i]\n",
    "\n",
    "        trip_info = {\n",
    "            \"user_2\": user_2,\n",
    "            \"trip_destination\": trip['item'],\n",
    "            \"trip_friends\": trip_friend,\n",
    "            \"trip_country\": trip['country'],\n",
    "        }\n",
    "        user_dataset[user][\"trip_info\"].append(trip_info)\n",
    "# user_dataset\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset to a JSON file\n",
    "output_file = '../../Dataset_Helping/S_Uni/S_Uni_Structured.jsonl'\n",
    "with open(output_file, 'w') as f:\n",
    "    for user, data in user_dataset.items():\n",
    "        line = {'user': user, 'trip_info': data['trip_info']}\n",
    "        f.write(json.dumps(line) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 records from structured data file\n",
      "Loaded 1500 records from generated data file\n",
      "{'user': 'Elita', 'trip_info': [{'user_2': 'Creighton', 'trip_destination': 'Ictus Theatre', 'trip_friends': 'Sigil', 'trip_country': 'Chile', 'type_of_location': ['building', 'venue']}, {'user_2': 'Guinlan', 'trip_destination': 'Laudation of the Virgin church at Ratmino', 'trip_friends': 'Weiland', 'trip_country': 'Russia', 'type_of_location': ['church building', 'architectural landmark']}, {'user_2': 'Hachiko', 'trip_destination': \"Jong's Crocodile Farm and Zoo\", 'trip_friends': 'Allegria', 'trip_country': 'Malaysia', 'type_of_location': ['zoo', 'crocodile farm']}, {'user_2': 'Raleigh', 'trip_destination': 'Stanga House', 'trip_friends': 'Lochlann', 'trip_country': 'Switzerland', 'type_of_location': ['museum building', 'architectural structure']}, {'user_2': 'Silvin', 'trip_destination': 'Rates Ecomuseum', 'trip_friends': 'Odette', 'trip_country': 'Portugal', 'type_of_location': ['museum']}, {'user_2': 'Fable', 'trip_destination': 'Sovelius house', 'trip_friends': 'Elix', 'trip_country': 'Finland', 'type_of_location': ['museum', 'building', 'main house', 'residential building']}, {'user_2': 'Rashika', 'trip_destination': 'Thission Outdoor Summer Cinema', 'trip_friends': 'Adriel', 'trip_country': 'Greece', 'type_of_location': ['outdoor cinema', 'movie theater']}, {'user_2': 'Anuhea', 'trip_destination': 'Natatorium Heveney', 'trip_friends': 'Zephra', 'trip_country': 'Germany', 'type_of_location': ['swimming center']}, {'user_2': 'Candide', 'trip_destination': 'Cathedral of St. Francis of Assisi', 'trip_friends': 'Idrienne', 'trip_country': 'Colombia', 'type_of_location': ['Catholic cathedral']}, {'user_2': 'Camren', 'trip_destination': 'Dir Museum', 'trip_friends': 'Dulcina', 'trip_country': 'Pakistan', 'type_of_location': ['museum']}, {'user_2': 'Melitta', 'trip_destination': 'Last Supper Chapel', 'trip_friends': 'Jariel', 'trip_country': 'Czech Republic', 'type_of_location': ['chapel']}, {'user_2': 'Thyra', 'trip_destination': 'Adamson University', 'trip_friends': 'Glynnis', 'trip_country': 'Philippines', 'type_of_location': ['university']}, {'user_2': 'Mirabel', 'trip_destination': 'Cadillac Arena', 'trip_friends': 'Quetzalee', 'trip_country': \"People's Republic of China\", 'type_of_location': ['stadium']}, {'user_2': 'Varian', 'trip_destination': 'Heni Church', 'trip_friends': 'Haiden', 'trip_country': 'Norway', 'type_of_location': ['church building']}, {'user_2': 'Lian', 'trip_destination': 'Buta Palace', 'trip_friends': 'Nephele', 'trip_country': 'Azerbaijan', 'type_of_location': ['venue']}, {'user_2': 'Xanthe', 'trip_destination': 'Stilohal', 'trip_friends': 'York', 'trip_country': 'Netherlands', 'type_of_location': ['sports complex']}, {'user_2': 'Phyllis', 'trip_destination': 'Rhema Chapel', 'trip_friends': 'Anila', 'trip_country': 'Nigeria', 'type_of_location': ['church building']}, {'user_2': 'Telena', 'trip_destination': 'Tuida', 'trip_friends': 'Klyra', 'trip_country': 'Bulgaria', 'type_of_location': ['hill', 'museum', 'fortress']}, {'user_2': 'Byron', 'trip_destination': 'Trautvetter Chapel', 'trip_friends': 'Korra', 'trip_country': 'Lithuania', 'type_of_location': ['chapel']}, {'user_2': 'Elysia', 'trip_destination': 'Sosura memorial museum', 'trip_friends': 'Ygraine', 'trip_country': 'Ukraine', 'type_of_location': ['museum']}, {'user_2': 'Ciriella', 'trip_destination': 'St. Kajo', 'trip_friends': 'Farrah', 'trip_country': 'Croatia', 'type_of_location': ['chapel']}, {'user_2': 'Casilda', 'trip_destination': 'St. Onuphrius Church', 'trip_friends': 'Harlow', 'trip_country': 'Slovenia', 'type_of_location': ['abbey church']}, {'user_2': 'Ellian', 'trip_destination': 'National Archives of Modern Architecture', 'trip_friends': 'Linnaeus', 'trip_country': 'Japan', 'type_of_location': ['national archives', 'architectural museum']}, {'user_2': 'Julina', 'trip_destination': 'Black Saracen Pharmacy Museum', 'trip_friends': 'Moriana', 'trip_country': 'Hungary', 'type_of_location': ['museum']}, {'user_2': 'Kendry', 'trip_destination': 'Salsali Private Museum', 'trip_friends': 'Quester', 'trip_country': 'United Arab Emirates', 'type_of_location': ['museum']}, {'user_2': 'Abra', 'trip_destination': \"Cleeve's Tunnel\", 'trip_friends': 'Vale', 'trip_country': 'South Africa', 'type_of_location': ['recreational dive site', 'offshore dive site']}, {'user_2': 'Mauve', 'trip_destination': 'Shaftesbury Street Methodist Chapel', 'trip_friends': 'Erling', 'trip_country': 'United Kingdom', 'type_of_location': ['chapel']}, {'user_2': 'Laurel', 'trip_destination': 'Cathedral of St. Charles Borromeo', 'trip_friends': 'Lanesha', 'trip_country': 'Costa Rica', 'type_of_location': ['Catholic cathedral']}, {'user_2': 'Jayna', 'trip_destination': 'Fort Lugard', 'trip_friends': 'Kataleia', 'trip_country': 'Uganda', 'type_of_location': ['fort', 'museum']}, {'user_2': 'Robichaux', 'trip_destination': 'Inatura', 'trip_friends': 'Nysiah', 'trip_country': 'Austria', 'type_of_location': ['museum', 'natural history museum']}]}\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 82\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     81\u001b[39m     base_path = \u001b[33m'\u001b[39m\u001b[33m../../../Dataset_Generation/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[43mmerging_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mmerging_dataset\u001b[39m\u001b[34m(base_path)\u001b[39m\n\u001b[32m     52\u001b[39m hour = random.randint(\u001b[32m8\u001b[39m, \u001b[32m17\u001b[39m)\n\u001b[32m     53\u001b[39m minute = \u001b[38;5;28msorted\u001b[39m(random.sample(\u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m60\u001b[39m), \u001b[32m10\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m conversation = [(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversation[s][\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhour\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminute[s]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, conversation[s][\u001b[32m1\u001b[39m], \u001b[43mconversation\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(conversation))]\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# user_response = generated_data[int(i*20 + j)]\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# if conversation == '-':\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m#     print(conversation, i*20 + j)\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m#     raise Exception(\"conversation is '-'\")\u001b[39;00m\n\u001b[32m     63\u001b[39m question = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWhat did \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m go to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrip_info_list[j][\u001b[33m'\u001b[39m\u001b[33mtrip_country\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with?\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mIndexError\u001b[39m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from datetime import timedelta, date, datetime\n",
    "import ast\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "# ------------------------------------------------------------\n",
    "# Initialize random seed\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "def merging_dataset(base_path):\n",
    "\n",
    "    # Load the structured data\n",
    "    structured_data_path = base_path + \"Dataset_Helping/S_Uni/S_Uni_Structured.jsonl\"\n",
    "\n",
    "    with open(structured_data_path, 'r', encoding='utf-8') as f:\n",
    "        structured_data = [json.loads(line) for line in f]\n",
    "\n",
    "    print(f\"Loaded {len(structured_data)} records from structured data file\")\n",
    "\n",
    "    # Load the generated conversation data\n",
    "    generated_data_path = base_path + \"Dataset_Helping/S_Uni/S_Uni_Structured_Generated_conversation.jsonl\"\n",
    "\n",
    "    with open(generated_data_path, 'r', encoding='utf-8') as f:\n",
    "        generated_data = [json.loads(line) for line in f]\n",
    "\n",
    "    print(f\"Loaded {len(generated_data)} records from generated data file\")\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "\n",
    "    x = 0\n",
    "    for i in range(len(structured_data)):\n",
    "        print(structured_data[i])\n",
    "\n",
    "        user_ID = i\n",
    "        user = structured_data[i]['user']\n",
    "        trip_info_list = structured_data[i]['trip_info']\n",
    "\n",
    "        for j in range(len(trip_info_list)):\n",
    "            user_2 = trip_info_list[j]['user_2']\n",
    "            if i*30 + j != x:\n",
    "                print(i*30 + j, x)\n",
    "            assert i*30 + j == x\n",
    "            x += 1\n",
    "            conversation = generated_data[int(i*20 + j)]\n",
    "            conversation = ast.literal_eval(conversation.replace('\\\\', ''))\n",
    "\n",
    "\n",
    "            hour = random.randint(8, 17)\n",
    "            minute = sorted(random.sample(range(0, 60), 10))\n",
    "\n",
    "            # user_response = generated_data[int(i*20 + j)]\n",
    "            if conversation == '-':\n",
    "                print(conversation, i*20 + j)\n",
    "                raise Exception(\"conversation is '-'\")\n",
    "\n",
    "            conversation = [(f\"{conversation[s][0]} {hour:02d}:{minute[s]:02d}\", conversation[s][1], conversation[s][2]) for s in range(len(conversation))]\n",
    "\n",
    "\n",
    "            question = f\"What did {user} go to {trip_info_list[j]['trip_country']} with?\"\n",
    "            dataset.append({\n",
    "                \"user_ID\": user_ID,\n",
    "                \"user\": user,\n",
    "                \"user_2\": user_2,\n",
    "                \"conversation\": conversation,\n",
    "                \"extra_info\": {k:v for k,v in trip_info_list[j].items() if k in ['type_of_location']},\n",
    "                \"question\": question,\n",
    "                \"answer\": trip_info_list[j]['trip_friends']\n",
    "            })\n",
    "\n",
    "    with open(base_path + '/Data/S_Uni.jsonl', 'w', encoding='utf-8') as f:\n",
    "        for item in dataset:\n",
    "            json.dump(item, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "    print(f\"S_Uni: {len(dataset)}, stored in {base_path}/Data/S_Uni.jsonl\")\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    base_path = '../../../Dataset_Generation/'\n",
    "    merging_dataset(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
