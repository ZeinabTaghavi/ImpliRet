{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying with offset 0...\n",
      "Saved 11 records to wikidata_all_info.jsonl\n",
      "Completed: 11 total records saved to wikidata_all_info.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Unified SPARQL script: fetch base and detailed info in one query\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "from typing import Dict, List\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "# Use specific GPUs if needed\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,...\"\n",
    "\n",
    "\n",
    "def create_session() -> requests.Session:\n",
    "    \"\"\"Create a requests session with retry logic.\"\"\"\n",
    "    session = requests.Session()\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        backoff_factor=1,\n",
    "        status_forcelist=[429, 500, 502, 503, 504]\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "    return session\n",
    "\n",
    "\n",
    "def query_wikidata(session: requests.Session, query: str, headers: Dict[str, str], offset: int = 0, limit: int = 5000) -> List[Dict]:\n",
    "    \"\"\"Execute a SPARQL query on Wikidata with pagination and return the raw bindings.\"\"\"\n",
    "    url = \"https://query.wikidata.org/sparql\"\n",
    "    paginated_query = f\"{query}\\n LIMIT {limit} \\n OFFSET {offset}\\n\" + '''\n",
    "  }\n",
    "  OPTIONAL { ?item wdt:P17 ?country.      ?country rdfs:label ?countryLabel.      FILTER(LANG(?countryLabel)=\"en\") }\n",
    "  OPTIONAL { ?item wdt:P131 ?adminEntity. FILTER NOT EXISTS { ?adminEntity wdt:P31 wd:Q515. } ?adminEntity rdfs:label ?adminEntityLabel. FILTER(LANG(?adminEntityLabel)=\"en\") }\n",
    "  OPTIONAL { ?item wdt:P131 ?city. FILTER EXISTS { ?city wdt:P31 wd:Q515. } ?city rdfs:label ?cityLabel. FILTER(LANG(?cityLabel)=\"en\") }\n",
    "  OPTIONAL { ?item wdt:P276 ?loc.       ?loc rdfs:label ?locationLabel.       FILTER(LANG(?locationLabel)=\"en\") }\n",
    "  OPTIONAL { ?item wdt:P669 ?street.     ?street rdfs:label ?streetNameLabel.     FILTER(LANG(?streetNameLabel)=\"en\") }\n",
    "}\n",
    "    '''\n",
    "    try:\n",
    "        resp = session.get(\n",
    "            url,\n",
    "            params={\"query\": paginated_query, \"format\": \"json\"},\n",
    "            headers=headers,\n",
    "            timeout=30\n",
    "        )\n",
    "        resp.raise_for_status()\n",
    "        data = resp.json()\n",
    "        return data.get('results', {}).get('bindings', [])\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying Wikidata at offset {offset}: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def save_to_jsonl(records: List[Dict], output_file: str):\n",
    "    \"\"\"Append a list of dicts to a JSONL file.\"\"\"\n",
    "    try:\n",
    "        with open(output_file, 'a', encoding='utf-8') as f:\n",
    "            for rec in records:\n",
    "                f.write(json.dumps(rec, ensure_ascii=False) + '\\n')\n",
    "        print(f\"Saved {len(records)} records to {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to {output_file}: {e}\")\n",
    "\n",
    "\n",
    "def parse_binding(binding: Dict) -> Dict:\n",
    "    \"\"\"Extract simplified record from a single SPARQL binding.\"\"\"\n",
    "    def get_val(var: str) -> str:\n",
    "        return binding.get(var, {}).get('value', '')\n",
    "\n",
    "    uri = get_val('item')\n",
    "    # Utility to extract Q-number\n",
    "    qnum = lambda val: val.rsplit('/', 1)[-1] if '/' in val else val\n",
    "\n",
    "    return {\n",
    "        'itemQ': qnum(uri),\n",
    "        'itemLabel': get_val('itemLabel'),\n",
    "        'countryQ': qnum(get_val('country')),  \n",
    "        'countryLabel': get_val('countryLabel'),\n",
    "        'adminEntityQ': qnum(get_val('adminEntity')),\n",
    "        'adminEntityLabel': get_val('adminEntityLabel'),\n",
    "        'cityLabel': get_val('cityLabel'),\n",
    "        'locationLabel': get_val('locationLabel'),\n",
    "        'streetNameLabel': get_val('streetNameLabel')\n",
    "    }\n",
    "\n",
    "\n",
    "def main() -> List[Dict]:\n",
    "    \"\"\"Run unified SPARQL pipeline to fetch all info in one query.\"\"\"\n",
    "    # SPARQL query: union of classes plus optional detailed fields\n",
    "    base_query = '''\n",
    "PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "SELECT DISTINCT ?item ?itemLabel ?country ?countryLabel ?adminEntity ?adminEntityLabel ?cityLabel ?locationLabel ?streetNameLabel WHERE {\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "  {\n",
    "    SELECT DISTINCT ?item WHERE {\n",
    "      { ?item p:P31 ?s0. ?s0 (ps:P31/(wdt:P279*)) wd:Q17350442. } UNION\n",
    "      { ?item p:P31 ?s1. ?s1 (ps:P31/(wdt:P279*)) wd:Q4895393. } UNION\n",
    "      { ?item p:P31 ?s2. ?s2 (ps:P31/(wdt:P279*)) wd:Q464980. } UNION\n",
    "      { ?item p:P31 ?s3. ?s3 (ps:P31/(wdt:P279*)) wd:Q3918. } UNION\n",
    "      { ?item p:P31 ?s4. ?s4 (ps:P31/(wdt:P279*)) wd:Q33506. }\n",
    "    }\n",
    "\n",
    "'''\n",
    "    headers = {\n",
    "        \"User-Agent\": \"MyLandmarkQuery/1.0 (your.email@example.com)\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    batch_size = 10\n",
    "    offset = 0\n",
    "    output_file = 'wikidata_all_info.jsonl'\n",
    "    open(output_file, 'w').close()  # Reset output file\n",
    "\n",
    "    session = create_session()\n",
    "    all_records: List[Dict] = []\n",
    "\n",
    "    while True:\n",
    "        print(f\"Querying with offset {offset}...\")\n",
    "        \n",
    "        bindings = query_wikidata(session, base_query, headers, offset, batch_size)\n",
    "        if not bindings:\n",
    "            print(\"No bindings returned; ending.\")\n",
    "            break\n",
    "\n",
    "        records = [parse_binding(b) for b in bindings]\n",
    "        save_to_jsonl(records, output_file)\n",
    "        all_records.extend(records)\n",
    "\n",
    "        if len(bindings) < batch_size:\n",
    "            print(\"Final batch reached.\")\n",
    "            break\n",
    "        offset += batch_size\n",
    "        break\n",
    "        time.sleep(1)\n",
    "\n",
    "    session.close()\n",
    "    print(f\"Completed: {len(all_records)} total records saved to {output_file}\")\n",
    "    return all_records\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
